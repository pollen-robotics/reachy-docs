var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/help/debug/",title:"Debug",description:"Learn how you can debug Reachy.",content:""}),e.add({id:1,href:"/advanced/overview/full-kit/",title:"Full/Starter kit",description:"Overview of Reachy Full and Starter kits. Description and shematics of Reachy's torso and head hardware.",content:`Product #Starter kit Full kit Reachy\u0026rsquo;s torso #Front #(1) : Motors and fan’s housing for Orbita neck
(2) : Power board
(3) : Intel NUC embedded computer
(4) : Microphone
(5) : USB hub
(6) : Google Coral TPU
(7) : Right loudspeaker
(8) : Left loudspeaker
(9) : Loudspeakers volume button
Back #(10) : Hardware interface (see image below for details)
(11) : Fixations interface
(12) : Coral cooling/airing grid
Reachy\u0026rsquo;s hardware interface #(a) : Embedded computer on/off (NUC)
(b) : Ethernet port
(c) : USB-a 3.0 port (for cameras)
(d) : USB-a 2.0 port
(e) : USB-c port
(f) : HDMI port
(g) : Power supply port
(h) : Motors alimentation on/off
Reachy\u0026rsquo;s head #(13) : Right and left high quality motorized cameras and lenses
(14) : Antennas\u0026rsquo; motorized fixations
(15) : Head cables routing hole
`}),e.add({id:2,href:"/advanced/overview/",title:"Overview",description:"A quick overview of Reachy.",content:""}),e.add({id:3,href:"/advanced/overview/arm-kit/",title:"Arm kit",description:"What you can find in Reachy's arm kit.",content:`Product #Arm kit Reachy\u0026rsquo;s arm #(1) : 12V Power supply board (SMPS2Dynamixel)
(2) : USB to serial board (Need to be connected to your computer)
The arms specifications are available in section Arm mechanical specifications.
`}),e.add({id:4,href:"/advanced/specifications/",title:"Specifications",description:"A quick overview of Reachy.",content:""}),e.add({id:5,href:"/advanced/overview/mobile-base/",title:"Reachy + mobile base",description:"Reachy mobile robot composed of a Reachy full kit and a mobile base.",content:`Reachy + mobile base is composed of two parts:
a full kit Reachy robot (i.e. with two arms, torso and a head), an omnidirectional mobile base The mobile base communicates with Reachy using an USB cable plugged in Reachy\u0026rsquo;s back (see label (d) in schema Reachy\u0026rsquo;s hardware interface)
For more info on what is included in the mobile base, check the mobile base specifications.
`}),e.add({id:6,href:"/advanced/safety/",title:"Safety first",description:"Safety measures to take when using Reachy and it smobile base.",content:""}),e.add({id:7,href:"/advanced/software/",title:"Reachy's software",description:"Description of Reachy's software architecture.",content:""}),e.add({id:8,href:"/advanced/services/",title:"Services",description:"Use systemd services with Reachy.",content:""}),e.add({id:9,href:"/advanced/specifications/general-specs/",title:"General specifications",description:"Reachy's full/starter kit general specifications: material used for pieces, power consumption, dimensions, weight.",content:`Construction: 3D printed MJF Painted - Flexible PU molded - Aluminium
Max Power consumption: 180W
Full Kit Dimensions: 670x450x200mm (670x1800x200mm with arms outstretched)
Starter Kit Dimensions: 670x380x200mm (670x1008x200mm with arms outstretched)
Weight: 6.2kg without metal fixation
`}),e.add({id:10,href:"/advanced/specifications/arm-specs/",title:"Arm specifications",description:"Reachy's 2023 arm specifications: material used for pieces, power consumption, dimensions, weight, payload, degrees of freedom.",content:`Construction: 3D printed MJF Painted- 3 axial needle roller bearings
Power consumption: 51W
Dimensions: 662x88x73mm
Weight repartition #Overall Arm: 1670g
Shoulder: 240g
Upper arm: 610g
Forearm: 590g
Gripper: 230g
Maximum payload: 500g
(this may vary depending on the holding and duration configuration)
Degrees of freedom #Reachy\u0026rsquo;s arm offers 7 degrees of movement + 1 for the gripper
Right arm Left arm Motor name Angle limits Motor ID Motor name Angle limits Motor ID shoulder_pitch -150, 90 10 shoulder_pitch -150, 90 20 shoulder_roll -180, 10 11 shoulder_roll -10, 180 21 arm_yaw -90, 90 12 arm_yaw -90, 90 22 elbow_pitch -125, 0 13 elbow_pitch -125, 0 23 forearm_yaw -100, 100 14 forearm_yaw -100, 100 24 wrist_pitch -45, 45 15 wrist_pitch -45, 45 25 wrist_roll -55, 35 16 wrist_roll -35, 55 26 gripper -50, 25 17 gripper -25, 50 27 Motors 3 Dynamixel MX-106T 1 Dynamixel MX-64AT 4 Dynamixel MX-28AT Fans #3 fans (shoulder, elbow and wrist)
`}),e.add({id:11,href:"/advanced/specifications/gripper-specs/",title:"Gripper specifications",description:"Reachy's 2023 gripper specifications: material used for pieces, power consumption, dimensions, weight.",content:`Animated by 1 Dynamixel MX-28AT.
Includes a micro load cell 0.78 Kg
Construction: 3D printed MJF Painted - Flexible PU molded
Power consumption: 5.3W
Dimensions: 117.3x84x51.4mm
Weight: 0.3Kg
`}),e.add({id:12,href:"/advanced/specifications/head-specs/",title:"Head specifications",description:"Reachy's 2023 head specifications: material used for pieces, power consumption, dimensions, weight, cameras, description of neck joint and antennas.",content:`Construction: 3D printed MJF Painted.
Power consumption: 15W.
Dimensions: 175x253x108mm.
Weight: 0.675Kg.
Reachy’s head features two motorized high quality wide angle cameras, to observe its environment as well as being able to focus on the task of manipulating. The head is animated by Orbita, a unique technology developed by Pollen Robotics’ R\u0026amp;D team. This ball joint actuator allows unpreceded dynamic and multi-directional movement. With animated antennas, Reachy can convey many emotions to his audience.
See the head in action in this video:
Cameras #Dual 1080p@30fps camera with motorized zoom (FOV 65° to 125°), associated with 2 optical lenses.
Orbita neck joint #Ball joint actuator that is composed of a parallel mechanism motorized by 3 brushless Maxon motors. The control of each motor is done with a magnetic absolute encoder included on the electronic board on top of Orbita.
Antennas #Antennas are animated by a Dynamixel motor and are removable.
A system of 3 magnets allow the attachment of the antennas to the rotation axis.
`}),e.add({id:13,href:"/advanced/specifications/torso-specs/",title:"Torso specifications",description:"Reachy's 2023 torso specifications: material used for pieces, dimensions, weight and description of each hardware installed in it (computer, microphone, TPU, speaker, amplifier, power supply).",content:`Construction: 3D printed MJF Painted - Aluminium
Power consumption: 36W
Dimensions: 300x350x150mm
Weight: 1.7Kg
Reachy\u0026rsquo;s torso area includes the following elements:
Computer #Powerful internal computer NUC intel i5 quad-core 1.6Ghz with 16Go DDR4 and 256Go SSD (NUC8v5PN)
Microphone #Seeed Studio - ReSpeaker Mic Array v2.0: Microphone array for NLU (ReSpeaker) and a 3.5mm jack audio output
TPU #Embedded TPU Google Coral G950-01456-01 for running ML models inference at high speed locally
Speaker #2x 12W - 4Ohm Tectonic TEBM36S12 Speakers allowing stereo sound.
Amplifier #Drocking PAM8620 12V audio amplifier
Power supply #Mean Well - GST220A12-R7B180W - output 12V 15 A (input 85~264VAC - 120~370VDC)
`}),e.add({id:14,href:"/advanced/specifications/orbita-specs/",title:"Orbita specifications",description:"Orbita spherical joint specifications: material used for pieces, power consumption, dimensions, weight, gearbox, degrees of freedom and limit angles.",content:`Specifications #Construction: Aluminium machined and SLS printed parts - Custom steel gears - metal bearings and axes.
Power consumption: 8W
Voltage: 12V
No-load speed: 25rpm
Max Continous torque: 1.7Nm
Gear reduction ratio: 4.2666
Diameter: 70mm height: 170mm Weight: 850g
Motor + Gearbox specifications #Power consumption: 8W
Voltage: 12V
No-load speed: 105 rpm
Max Continous torque: 0.4 Nm
Gear reduction ratio: 35:1
Diameter: 22mm
Height: 75mm
Motor\u0026rsquo;s full specification here
Degrees of freedom #Orbita has 3 degrees of freedom actuated by three motors described above.
They correspond to three rotation at the same point like Roll Pitch Yaw rotations.
Angle limits
Roll: -46° to 46°
Pitch: -46° to 46°
Yaw: 360° full rotation
`}),e.add({id:15,href:"/advanced/specifications/mobile-base-specs/",title:"Mobile Base specifications",description:"Reachy's mobile base specifications: material used for pieces, power consumption, dimensions, weight, description of sensors, wheels and battery.",content:`Specifications #Construction:
Cylinder shape Aluminium, MJF 3D printed plastic parts, Steel Dimension: 50*25cm
Weight: 25kg
Payload: 80kg
Sensors:
Hall Sensors and IMU on each wheel RP Lidar S2 (30m radius distance, 32k measurments/s, 0.12° angle resolution, resistance to sunlight…) Wheels:
3x Omnidirectional wheels 300W Max power No-load speed: 210 rpm Stall Torque: 13Nm - 13A Rated load, speed and current : 5Nm, 115rpm, 5A Battery OlenBox M:
24V, 35Ah 19.5 x 17.2 x 13.4cm, 6.5kg 5 years warranty Equipped with a BMS for safety Battery state indicator Emergency Stop: The emergency stop can be placed on the robot or in the users hands. The E-stop instantly shuts down the entire robot.
`}),e.add({id:16,href:"/advanced/safety/correct-use/",title:"Use Reachy properly",description:"Safety measures with Reachy to protect the user and prevent the robot from damaging. Following this measures will ensure the longetivity of the robot.",content:`Don\u0026rsquo;t harm yourself\u0026hellip; #Even though there is little chance that you get hurt using Reachy, you might get surprised by its movements, especially the first times.
We recommend that you move both Reachy\u0026rsquo;s arms with your hands before you start programming it. The goal is that you get a sense of Reachy\u0026rsquo;s working space, the positions it can reach so that you won\u0026rsquo;t get hit when you actually send it commands.
Your browser does not support the video element.
and don\u0026rsquo;t harm Reachy! #There are a few things you need to know to make sure that your Reachy doesn\u0026rsquo;t get damaged when using it.
Don\u0026rsquo;t stay in stiff mode if you\u0026rsquo;re not moving the robot #Each Reachy\u0026rsquo;s motor can be in one of two compliance modes:
compliant: the motor is soft and can be freely turned by hand as in the video above. It cannot be controlled with code, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motor is hard and cannot be moved by hand. It can be controlled by setting new target position. In this mode, the motor use its maximum torque to maintain its present position until a target position is sent. You should hear a small noise coming from a motor in stiff mode, especially if you try to move it with your hands, it\u0026rsquo;s totally normal. Your browser does not support the video element.
Check out the Python SDK section on how to switch between the two modes.
🚨 What you need to keep in mind #You must be careful not to let the joints in stiff mode when you\u0026rsquo;re not using the robot. This mode can be really demanding for a motor, letting a motor in stiff mode will damage it after some time.
If an arm is lifted or if the neck is lowered, maintaining the position in stiff mode will be exhausting because the motors would have to compensate the gravity and they could get damaged. You can make the analogy with a human. If we ask you to keep stretched out arms, after a certain time it will be painful. So is the case for the joints of the robot.
Be aware of obstacles #When you are sending movements instructions to Reachy, mind the obstacles that could block Reachy during its movements.
For example, when you are asking to an arm to go between two positions, it will try to do it as hard as it can, whether or not there is something on its way. Also when you are moving both arms simultaneously, there are no safety measures implemented to prevent them from hitting each other. Nothing will also prevent Reachy\u0026rsquo;s arms from hitting its chest if you ask them to. If situations like these happen, don\u0026rsquo;t hesitate to use the motor\u0026rsquo;s switch in Reachy\u0026rsquo;s back to immediately turn off the motors so that Reachy\u0026rsquo;s motors will stop trying to reach a position they can\u0026rsquo;t get.
Check the temperatures #Reachy\u0026rsquo;s motors will heat when you are using its joints so you should manage the motors temperatures. The temperatures of each motor can be checked with the dashboard or be accessed using Reachy\u0026rsquo;s Python SDK.
There are two important temperature constants you need to know, their values depend on Reachy\u0026rsquo;s part:
fan trigger temperature: temperature at which the motor will start to get hot and the matching fan should be turned on automatically. The fans allow to work longer with hot joints but enventually the temperature will keep rising if the joints keep being sollicitated. The default value is 45°C on Reachy. shutdown temperature: when this temperature is reached, the motor will normally shutdown and stop working until it has cooled down. This is a precaution measure to protect the motor. The default value is 55°C on Reachy. Even though there exists a shutdown temperature, we recommand that when you intend on using the robot for a long period, you let the arms rest and their motors cool down regularly (5 minutes rest every 30 minutes of effort).
Good practices #Here is a non-exhaustive list of things to remember when you are using your Reachy, in order to make it last as long as possible.
Make sure that the robot is turned off and that the power supply is disconnected when you are not using it. Remember not to let the motors in stiff mode if you don\u0026rsquo;t plan to make them move. Even letting the arms on a table and in stiff mode for quite some time might damage them. Check that no obstacles will be on Reachy\u0026rsquo;s way when it will try to move. Sending commands to Reachy\u0026rsquo;s arms with an obstacle on the way will make the motors force as much as they can. Being in this kind of situation might happen but when this does, remember to turn off the motors immediately using the switch button in Reachy\u0026rsquo;s back. `}),e.add({id:17,href:"/advanced/safety/mobile-base/",title:"Use the mobile base properly",description:"Safety measures to follow with Reachy's mobile base.",content:`Basic mouvements #We recommend that you get a feel for the inertia of the robot by holding on to the metal pole and pushing and pulling it.
Block a wheel with your foot and try to gently tilt the robot.
Then use the controller to move around the robot as explained in Moving the mobile base
Your browser does not support the video element.
Common risks and advice #Even though the mobile base is programmed to move relatively slowly, it is important to try to avoid any potential collisions. The mobile base is designed to be used indoors on a flat surface.
💡 The arms and any grasped objects should ideally be in the vertical projection of the mobile base. The idea here is that the robot should always be able to rotate in place safely. Also, keeping the arms tugged in reduces the risk of tipping.
A low level collision avoidance safety always runs in the background, but it can only prevent collisions seen by the LIDAR. Read more about it in Anti-collision safety. A non exaustive list of cases where the safety can\u0026rsquo;t work:
Stairwells. There are no cliff sensors so the robot has no practical way of knowing it\u0026rsquo;s near downward stairs. A table. The LIDAR can see the legs but not the table top. A large clean bay window migh be invisible to the LIDAR. Small obstacles that fit below the LIDAR won\u0026rsquo;t be seen. Another risk is the robot tipping. Avoid rapid variations in acceleration. Also, we don\u0026rsquo;t recommend using the robot on a slope above 10°.
Battery management #We chose a high end battery for the mobile base. The Life4PO technology and the overal grade of the equipement (BMS, charger, monitoring system, certified UN 38.3, 5 years warranty), should make this one of the safest choices available on the market. However, the battery can hold a large amount of energy (832 Wh) and should always be treated carefully.
⚠️ Only use the dedicated charger to charge the battery
💡 When stocking the battery for long periods, aim for at least 60% charge
💡 Use the monitoring system (small screen on the mobile base) to recharge the battery before reaching 0% and relying on the BMS to shutdown the battery.
Dynamic capabilities #The wheel motors are very potent. In their default configuration, they are used at 20% of their maximum capabilities. You can, at your own risk, modify this limit in the configuration of the HAL.
`}),e.add({id:18,href:"/advanced/software/presentation/",title:"Overall presentation",description:"Presentation of the different components of Reachy's software and how they interact.",content:`Reachy\u0026rsquo;s software is composed of three main parts:
a HAL (Hardware Abstraction Layer) handling the communication with Reachy\u0026rsquo;s sensors i.e. the Dynamixel motors in the arms, fans, force sensors and Orbita actuator.
ROS packages: this is the core of the software. We are using ROS (Robotics Operating System), more precisely the ROS2 Humble distribution, and interact with the HAL via ros2 control. ROS packages are used to compute the kinematics for Reachy\u0026rsquo;s arms and Orbita, to get the camera feed and to manage the autofocus on Reachy\u0026rsquo;s motorised zooms.
Another ROS package is also used, along with gRPC, to create a server interacting with the different ROS nodes and services made for Reachy and allowing remote control on the robot without being physically connected to it.
gRPC client: the strength of using the gRPC framework is that we can have a remote control to the robot and create clients in any programming language (Python, C++, C#, \u0026hellip;). So knowing how to use ROS is not needed to work with Reachy.
Packages #The packages developed for Reachy 2023 are divided into two categories: the ROS packages and non-ROS packages.
ROS #(installed in ~/reachy_ws folder of Reachy\u0026rsquo;s computer)
The main package is reachy_2023. It contains multiple sub-packages:
reachy_description: publishes the robot\u0026rsquo;s URDF and control tag, needed by the kinematics package and by the different ROS simulation tools (rviz, gazebo, \u0026hellip;)
reachy_kdl_kinematics: computes the forward / inverse kinematics of Reachy\u0026rsquo;s arms and the forward / inverse kinematics of Orbita.
reachy_controllers: communicates with the HAL through ROS control hardware interface.
camera_controllers: communicates with the camera using v4l2 and zoom.
gripper_safe_controller: Smart gripper controller that automatically adjusts target position to avoid forcing.
reachy_msgs: specific ROS messages for Reachy
reachy_bringup: bringup launch file (can launch real, fake or gazebo reachy with or without RViz, etc.)
reachy_sdk_server: creates two gRPC servers, camera_server to get the camera\u0026rsquo;s images and control the motorised zooms and reachy_sdk_server for the joints, load sensors, fans and Orbita.
Mobile base #The following package is only needed if you have a Reachy with mobile base:
mobile_base_controller with the following sub-packages:
zuuu_hal: HAL dedicated to the mobile base zuuu_interfaces: custom ROS services for the mobile base mobile_base_sdk_server: creates a gRPC server to control the mobile base 💡 Zuuu is the internal name of the mobile base. It\u0026rsquo;s a french onomatopoeia that evokes swift mouvements :)
Non-ROS #(installed in ~/dev folder of Reachy\u0026rsquo;s computer)
The main library you will use:
reachy_sdk: SDK Python to control Reachy and develop applications Other dependencies for more specific use cases:
reachy_sdk_api: protobuf services and messages definition for the gRPC servers zoom_kurokesu: Python library to control Reachy\u0026rsquo;s motorized zooms Mobile base #The following package is only needed if you have a Reachy with mobile base:
mobile_base_sdk: SDK Python to control Reachy\u0026rsquo;s mobile base without necessarily having a Reachy robot connected. Controling the mobile base using reachy_sdk actually uses the mobile_base_sdk but hides it. gRPC clients #As explained, the gRPC clients permits the communication with the gRPC server through a network and without being physically connected on the robot. The gRPC clients can be installed on another machine and have few requisites, there is no need for the machine to have ROS installed on it.
gRPC clients can be in different programming languages. Currently, you can remotely control your robot using:
reachy_sdk: as described above, SDK Python to control Reachy\u0026rsquo;s arm, head, gripper. This is the library that we use when we want to develop an app on Reachy or test a new robot, mobile_base_sdk: SDK Python to control Reachy\u0026rsquo;s mobile base. It can work on the mobile base alone and with this, you don\u0026rsquo;t have to worry about whether or not Reachy\u0026rsquo;s motors are on or if Reachy\u0026rsquo;s main service is running. 💡 To learn more on the packages content and usage, please refer to README.md files of each directory.
👉 Want to get the latest software updates?Check how to do it here! Sum up #The diagram below sums up what has been described in this page.
`}),e.add({id:19,href:"/advanced/software/ros2-level/",title:"Working with ROS2 Humble",description:"Working at the ROS level of the robot. What are the different nodes available.",content:`Even if gRPC clients are available to control Reachy without knowing how to use ROS, you may want to work at the ROS level to implement new things for Reachy or use the tools provided by ROS. In this page, we will describe how to use the specfic ROS2 packages for Reachy.
Reachy runs natively on ROS2 Humble. ROS stands for Robotic Operating System, it offers a huge variety of compatible algorithms and hardware drivers.
The embedded NUC computer comes with ROS2 and Reachy specific packages already installed and running. They provide full access to Reachy. You can:
get the /joint_states and /dynamic_joint_states use Rviz to visualize your robot (either real or simulated) subscribe to various sensor topic (camera, force sensor, etc) publish position, torque, pid, etc commands using forward controller access client for IK/FK 💡 At this level, joints angles are handled in radians. NOTE: If you don\u0026rsquo;t know how to use ROS but still want to do it on Reachy, you should check the official ROS documentation, espcecially the tutorials showing examples and presenting the different key notions introduced by ROS.
What is runnning by default #If you have a Full kit or a Starter kit, reachy_sdk_server.service is enabled by default, meaninig that all Reachy ROS2 packages presented in the Overall presentation are automatically launched when you start the robot.
If you have a Reachy mobile, reachy_mobile_base.service is enabled along with reachy_sdk_server.service.
See section Using services for more information on the services.
You can check all ROS2 topics/services running on Reachy with:
ros2 topic listand
ros2 service listUsing launch files directly #The following presents what launch files can be launched, if you don\u0026rsquo;t whant to use the service. If you want to learn more about what is run by each launch file, check the README of the corresponding package.
Bringup #The launch file reachy.launch.py is the main entry point. It is reponsible for launching everything you need to use your Reachy. It can either connect to a real Reachy or simulate a fake one. You can run the sdk server or not, etc.
To connect to your robot and run everything needed to control it via ROS you can simply run:
ros2 launch reachy_bringup reachy.launch.pyIf you want to control it using the SDK (that is what is done by default by Reachy\u0026rsquo;s main service reachy_sdk_server.service):
ros2 launch reachy_bringup reachy.launch.py start_sdk_server:=trueSimilarly, if you want to control a fake Reachy using the SDK, you can run (we also launch RViz so you can see what\u0026rsquo;s going on):
ros2 launch reachy_bringup fake:=true start_sdk_server:=true start_rviz:=trueOther options are available and can be seen below:
ros2 launch reachy_bringup reachy.launch.py --show-argsArguments (pass arguments as '\u0026lt;name\u0026gt;:=\u0026lt;value\u0026gt;'):'start_rviz':Start RViz2 automatically with this launch file. Valid choices are: ['true', 'false'](default: 'false')'fake':Start on fake_reachy mode with this launch file. Valid choices are: ['true', 'false'](default: 'false')'gazebo':Start a fake_hardware with gazebo as simulation tool. Valid choices are: ['true', 'false'](default: 'false')'start_sdk_server':Start sdk_server along with reachy nodes with this launch file. Valid choices are: ['true', 'false'](default: 'false')This launch file actually runs many other launch files. If you want to have your custom launch file, the better way is probably to directly have a look at what\u0026rsquo;s inside.
Cameras nodes #Cameras nodes are available for full/starter kit only:
To run the camera view node ROS services:
ros2 run camera_controllers camera_publisherTo launch the camera zoom node ROS services:
ros2 run camera_controllers camera_zoom_serviceTo launch the camera focus node ROS services:
ros2 run camera_controllers camera_focusKinematics nodes #The Kinematics services are available to provide inverse and forward kinematics services for the arms, as well as inverse kinematics for the neck. They are launched automatically by the bringup launch file.
If you need to run them separately:
ros2 run reachy_kdl_kinematics reachy_kdl_kinematicsIt requires the robot_state_publisher to be running.
Mobile base #To launch the mobile base Hardware Abstraction Layer node:
ros2 launch zuuu_hal hal.launch.pyMany parameters on the mobile base like the maximum velocity can only be tuned at the ROS level. Check the mobile base\u0026rsquo;s HAL README to learn about what you can do with the mobile base at the ROS level.
SDK server nodes #A layer above ROS, you can interact with Reachy SDK API. The Python SDK offers a gRPC (Remote Procedure Call) interface to communicate with the server.
To communicate with Reachy through the SDK, you need to launch server nodes that handle gRPC services. The easiest way is to use the special flag start_sdk_server:=true in the bringup launch file. But if you want to run it independently:
To launch the node for the joints, fans and kinematics gRPC services:
ros2 run reachy_sdk_server reachy_sdk_serverTo launch the node for the cameras view and zoom gRPC services (full/starter kit only):
ros2 run reachy_sdk_server camera_serverNote: For the servers to work, the required ROS services must be already launched. The easiest way is via the bringup launch file.
To launch the node for the mobile base gRPC services (mobile kit only):
ros2 launch mobile_base_sdk_server mobile_base_sdk_server.launch.py`}),e.add({id:20,href:"/advanced/software/configuration-file/",title:"Reachy's configuration file",description:"Reachy's configuration file is used to indicate which Reachy's configuration your robot has and whether a mobile base is connected to the robot or not.",content:`We created a custom yaml file (~/.reachy.yaml) to indicate which Reachy\u0026rsquo;s configuration your robot has and whether a mobile base is connected to the robot or not. Having this file is useful to start only the necessary code required by the Reachy version you are using.
This file is read when Reachy\u0026rsquo;s main services are launched at boot or by the bringup launch file.
The configuration file has multiple entries:
model: model of your Reachy (if it is a full kit, a starter kit, \u0026hellip;). When reachy_sdk_server.service starts, it will look at this entry to choose what code it has to run depending on the model of the robot. zuuu_model: is at None if no mobile base is attached with the robot, else the mobile base version is indicated (current mobile base version is 1.2). When reachy_mobile_base.service starts, if zuuu_model is not None, the mobile base code is launched. neck_zero_hardware: hardware position of the three disks. You should not need to change those values unless you changed Orbita. fan_trigger_temperature: temperature used to determine whether or not Reachy\u0026rsquo;s fans need to be turned on to cool the motors off. The default value is 45°C. Typically, ~/.reachy.yaml looks like this:
generation: 2023model: full_kitzuuu_version: 1.2neck_orbita_zero:top: 0.0middle: 0.0bottom: 0.0fan_trigger_temperature: 45camera_parameters:left:fx: 0.0fy: 0.0cx: 0.0cy: 0.0k1: 0.0k2: 0.0k3: 0.0p1: 0.0p2: 0.0right:fx: 0.0fy: 0.0cx: 0.0cy: 0.0k1: 0.0k2: 0.0k3: 0.0p1: 0.0p2: 0.0You can find a template here.
`}),e.add({id:21,href:"/advanced/services/available/",title:"Available system services",description:"Core services running on Reachy.",content:`System services are available on the robot to automatically launch at boot the most commonly used features of the robot. It is useful when you just want to use our Python SDK without having to worry about running by hand Reachy\u0026rsquo;s core ROS code. Nevertheless, you may want to use Reachy differently and deactivate them.
We use system.d to handle the services. If you are not familiar with this system, you should refer to the official documentation.
💡 The services are in user mode and stored in ~/.config/systemd/user.
Services available #reachy_sdk_server.service #For each Reachy\u0026rsquo;s configuration except for the Arm kit (i.e. Full, Starter and Mobile kit), the service reachy_sdk_server.service is available and enabled by default.
You can see how the service is defined on reachy_sdk_server repository but basically what this service does is executing a bash file which itself executes the ROS command:
ros2 launch reachy_bringup reachy.launch.py start_sdk_server:=trueThe bringup launch file will start each useful Reachy\u0026rsquo;s ROS node like a node to handle the joints, one for the kinematics, another for the cameras (if Reachy\u0026rsquo;s configuration has a head), \u0026hellip;
For the complete list of the ROS nodes launched by the service, check reachy.launch.py file.
reachy_mobile_base.service #If your Reachy is equipped with a mobile base, the service reachy_mobile_base.service is also available and enabled by default. Having separate services for Reachy and the mobile base allows to work separately with the mobile base or Reachy when you have a Reachy Mobile.
As reachy_sdk_server.service, reachy_mobile_base.service is defined in the mobile_base_sdk_server repository. The service executes a bash file which itself executes the ROS command:
ros2 launch mobile_base_sdk_server run_mobile_base_sdk_server_and_hal.launch.pyif a mobile base version is specified in Reachy\u0026rsquo;s configuration file.
The launch file launched will start the ROS nodes for the HAL of the mobile base and the node to start the gRPC SDK server to use the mobile base Python SDK.
For the complete list of the ROS nodes launched by the service, check run_mobile_base_sdk_server_and_hal.launch.py.
reachy_dashboard.service #The reachy_dashboard.service is also available and enabled by default on each Reachy. This service makes sure that the dashboard is started when the robot boots and that you can check its IP address on the LCD screen installed in its back.
What if I don\u0026rsquo;t want to use services #If you don\u0026rsquo;t want to use the default services, you can simply disable them so that they won\u0026rsquo;t start when booting the robot and launch Reachy\u0026rsquo;s ROS launch files by hand.
`}),e.add({id:22,href:"/advanced/services/manage-services/",title:"Manage Reachy's services",description:"Manage Reachy's core services.",content:`Use the dashboard! #Each Reachy\u0026rsquo;s service appear in the services page of the dashboard. A card is created for each service with three buttons: restart (to restart the service), stop (to stop it) and show logs (to have acces to the status of the service and check what is happening, useful for debug). Using the dashboard is the easiest way to manage Reachy\u0026rsquo;s services.
💡 A card will be created for one of Reachy\u0026rsquo;s services only if the service is enabled.
Manage the services by hand #It is of course possible to manage the services using CLI. The following commands are taken from systemd documentation. For more details, don\u0026rsquo;t hesitate to check the documentation directly.
Start, restart or stop a service #Eachy Reachy\u0026rsquo;s services can be started, stopped or restarted by hand. It can be useful for situations where for example you turned Reachy\u0026rsquo;s computer on but forgot to turn on its motors. By restarting reachy_sdk_server.service, you would not have to reboot Reachy\u0026rsquo;s computer.
To start a specific service like reachy_sdk_server.service, type the following command in a terminal:
systemctl --user start reachy_sdk_server.serviceSimilarly, you can stop or restart a specific service by replacing the start keyword by either stop or restart. For example, to restart reachy_sdk_server.service, the command is:
systemctl --user restart reachy_sdk_server.serviceNote: if you stop a service, it will start again automatically at the next boot of Reachy\u0026rsquo;s computer. If you would prefer to always have the service stopped, you will have to disable it.
Get a service status #Having a service\u0026rsquo;s status can be really useful for debugging. With it you can know whether the service is active or not and especially, you can have access to the latest logs of the service. For example if you can\u0026rsquo;t connect to your Reachy or the mobile base with the Python SDK, there is probably a message in the service explaining why the code has crashed.
To get the status of a service like reachy_sdk_server.service, use
systemctl --user status reachy_sdk_server.serviceEnable or disable a service #There are situations when you would prefer to disable a service completely so that it is never started when Reachy\u0026rsquo;s computer is booting. It might be for example because you would prefer to start Reachy\u0026rsquo;s ROS code by hand to have a finer control on it.
If that is the case, you can disable a service like reachy_sdk_server.service with
systemctl --user disable reachy_sdk_server.serviceAt any time, if you prefer to work with the service again, you can enable it.
systemctl --user enable reachy_sdk_server.service`}),e.add({id:23,href:"/dashboard/installation/hardware/",title:"Hardware to display Reachy's IP address",description:"How is Reachy's IP address displayed in the robot.",content:` Please note that the LCD display screen should be installed in the back of the torso of your Reachy. You will need to take off Reachy\u0026rsquo;s tee shirt to see it.
Hardware #To display Reachy\u0026rsquo;s IP address, four components are needed:
LCD display Arduino Nano Every cables to solder between the LCD and the Arduino a micro USB cable to connect the Arduino to Reachy\u0026rsquo;s NUC. Flashing the Arduino #The code for the Arduino can be found here. Basically, it just listens to messages containing the IP address coming from Reachy\u0026rsquo;s NUC on the serial bus, recovers the IP and displays it on the LCD screen.
The Arduino IDE will be needed to flash the Arduino.
Wiring #GND pin of the LCD display goes with GND pin of the Arduino VCC pin of the LCD display goes with 5V pin of the Arduino SCL pin of the LCD display goes with A5 pin of the Arduino SDA pin of the LCD display goes with A4 pin of the Arduino `}),e.add({id:24,href:"/dashboard/installation/software/",title:"Software installation",description:"How the dashboard is installed in Reachy.",content:` Please note that the dashboard should be installed and its main service enabled by default on your Reachy.
Clone the repository #Clone the repository reachy-dashboard from GitHub and use pip to install it.
cd ~/devgit clone https://github.com/pollen-robotics/reachy-dashboardcd reachy-dashboardpip3 install -e .Check Reachy\u0026rsquo;s services #To be able to control Reachy\u0026rsquo;s main services with the dashboard, the services need to be in \u0026ndash;user mode. To know if it is the case, in a terminal:
systemctl --user list-unit-files | grep reachyCreate Reachy\u0026rsquo;s Hotspot #nmcli dev wifi hotspot ifname wlp0s20f3 con-name Reachy-AP ssid Reachy-AP password \u0026quot;Reachy-AP\u0026quot;Create a service file #Create a service file so that the dashboard will be started automatically at boot along with Reachy\u0026rsquo;s main services. One advantage of having this is that the dashboard will be running when you start the robot, so you won\u0026rsquo;t need to plug a screen computer to Reachy nor scan the network to get its IP address and connect to it. The IP address of the robot on the network will be displayed on the LCD screen (if you installed it).
To create the service:
cd ~/dev/reachy-dashboardbash setup_service.bashsystemctl --user enable reachy_dashboard.servicesystemctl --user start reachy_dashboard.service`}),e.add({id:25,href:"/vr/installation/installation/",title:"What needs to be installed",description:"What you need to install to control Reachy with the VR application.",content:` 👉 Reachy 2021/2023 is already fully compatible with the teleoperation application. You have nothing to install on the robot. ⬇️ Download the latest version of the app On the Oculus Quest 2 #There are two options for this device: use it natively on the headset or run it on your computer using an Oculus link. If you want to use the Oculus Link, please refer to the On Windows computer section. To use it natively, choose one of the following options to install it.
From the Quest Store #Contact us at support@pollen-robotics.com to be added to the list of the beta testers.
Using the apk #Download the apk from our github repo, and install it to your device with your favorite tool (with the meta quest developer hub for instance).
On the Windows computer #Make sure that your VR device is properly installed and running (please refer to your device documentation).
Download the zip archive from our github repo, and unzip it. Simply launch the TeleopReachy.exe file to start the application.
`}),e.add({id:26,href:"/vr/installation/",title:"VR Installation",description:"",content:""}),e.add({id:27,href:"/docs/installation/use-vr/",title:"Use VR teleoperation app",description:"Control the robot through VR teleoperation.",content:`Reachy 2023 is fully compatible with the VR teleoperation application. You do not need to install anything else on your robot.
Please refer to the teleoperation application documentation for the installation details on the remote computer.
Getting started with Reachy VR teleoperation app `}),e.add({id:28,href:"/docs/installation/use-sdk/",title:"Use Reachy SDK",description:"Control the robot from any computer using the SDK.",content:`If you want to control Reachy using its Python SDK, you only need to install it on the computer you want to use. The SDK is a pure Python library so it can be easily installed on any computer running Python \u0026gt;= 3.6.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='reachy.IP.address')Ready to start using the Python SDK? Check out the Python SDK documentation!
Getting started with Reachy Python SDK `}),e.add({id:29,href:"/docs/installation/full-installation-process/",title:"Software installation process",description:"Full/Starter kit installation process.",content:`You decided to buy a Full/Starter kit, congratulations! You just saved a lot of time ;)
Everything you need is already installed on your robot.
Of course you may want to know what\u0026rsquo;s included in it. Please refer to section What is running/What can I run on my robot for more information.
For Arm kit only:
I have an Arm kit. What do I need to do? `}),e.add({id:30,href:"/docs/installation/arm-installation-process/",title:"Arm Installation Process",description:`You decided to buy an Arm kit, you have a few things to install on your computer. Don’t worry, we will go step by step to guide you through the installation process!
Prerequisites #The low-level software used to control the robot has been developed to work on Linux Ubuntu 22.04. While it should work on other OS, we strongly recommend using the same version.
Presentation #Reachy\u0026rsquo;s software installation is divided into two main parts:`,content:`You decided to buy an Arm kit, you have a few things to install on your computer. Don’t worry, we will go step by step to guide you through the installation process!
Prerequisites #The low-level software used to control the robot has been developed to work on Linux Ubuntu 22.04. While it should work on other OS, we strongly recommend using the same version.
Presentation #Reachy\u0026rsquo;s software installation is divided into two main parts:
installing ROS2 Humble and the ROS2 packages developped for Reachy installing the Python packages developped for Reachy If you are not familiar with ROS, it stands for Robotics Operating System and is basically a set of software libraries and tools that help build robot applications. It is commonly used in Robotics. You don\u0026rsquo;t need to know how to use ROS to work with Reachy thanks to the Python SDK that we developped but if you want to learn about ROS, we suggest taking a look at their great tutorials.
Also, you can check this page to know more about how Reachy\u0026rsquo;s software is organised.
Now back to the installation!
Install ROS2 Humble #As explained above, Reachy\u0026rsquo;s software runs on ROS 2 Humble so first of all, you need to install it on your computer. Based on the official ROS2 documentation, here are the steps to do the installation. In a terminal, in your computer:
sudo apt update \u0026amp;\u0026amp; sudo apt install -y localessudo locale-gen en_US en_US.UTF-8sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8export LANG=en_US.UTF-8sudo apt install -y software-properties-commonsudo add-apt-repository universesudo apt update \u0026amp;\u0026amp; sudo apt install -y curlsudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpgecho \u0026quot;deb [arch=\$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu \$(. /etc/os-release \u0026amp;\u0026amp; echo \$UBUNTU_CODENAME) main\u0026quot; | sudo tee /etc/apt/sources.list.d/ros2.list \u0026gt; /dev/nullsudo apt updatevcs import src \u0026lt; ros2_control.repossudo apt install -y ros-humble-desktopsudo apt install -y ros-dev-toolssudo apt install -y ros-humble-tf-transformationssudo apt install -y ros-humble-compressed-image-transportsudo apt install -y python3-colcon-common-extensionsCheck that the installation went well #To make sure that ROS2 Humble has been successfully installed, you can run the test example from ROS2 Humble. Taken from the ROS2 Humble documentation.
Install Reachy\u0026rsquo;s ROS2 packages #Create a dedicated workspace #Now that you have installed ROS, you need to create a ROS workspace to install the specific ROS packages for Reachy.
Create it in your \$HOME folder:
mkdir -p ~/reachy_ws/srcBuild your empty workspace once to set everything up.
cd ~/reachy_wssource /opt/ros/humble/setup.bashcolcon build --symlink-installOnce done, add commands to your .bashrc file so that you won\u0026rsquo;t have to type them in each new terminal.
echo \u0026quot;source /opt/ros/humble/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho \u0026quot;source /home/reachy/reachy_ws/install/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho \u0026quot;source /usr/share/colcon_cd/function/colcon_cd.sh\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho \u0026quot;export _colcon_cd_root=~/ros2_install\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho 'export LC_NUMERIC=\u0026quot;en_US.UTF-8\u0026quot;' \u0026gt;\u0026gt; ~/.bashrcecho \u0026quot;export RMW_IMPLEMENTATION=rmw_cyclonedds_cpp\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho \u0026quot;export ROS_DOMAIN_ID=1\u0026quot; \u0026gt;\u0026gt; ~/.bashrcIn the seconde line, replace the reachy in /home/reachy/reachy_ws/install/setup.bash with your username.
Finally, source your .bashrc file:
source ~/.bashrcInstall git lfs #sudo apt-get install -y git-lfsgit lfs installClone Reachy\u0026rsquo;s ROS2 packages #Now you\u0026rsquo;re ready to install Reachy\u0026rsquo;s ROS2 packages in the workspace you just created.
reachy_2023 cd ~/reachy_ws/srcgit clone https://github.com/pollen-robotics/reachy_2023.gitOnce everything cloned in your ROS2 workspace, install the dependencies and build the packages:
cd ~/reachy_wsbash ./src/reachy_2023/dependencies.shpip3 install -r ./src/reachy_2023/requirements.txtcolcon build --symlink-installInstall Reachy\u0026rsquo;s Python packages #Other ependencies #Some of Reachy\u0026rsquo;s Python packages have dependencies that you should install. The dependencies are numpy, scipy, pyquaternion, sklearn, pykdl.
Using pip install: pip3 install numpypip3 install scipypip3 install pyquaternionpip3 install sklearnWe also recommend to install the jupyter and matplotlib libraries.
pip3 install jupyterpip3 install matplotlibCloning the Python packages #Create another folder dev that will contain all the packages used with Reachy that are not based on ROS.
mkdir ~/devIn this folder you will need the following repositories:
reachy_sdk_api reachy-sdk cd ~/devgit clone https://github.com/pollen-robotics/reachy-sdk-api.gitgit clone https://github.com/pollen-robotics/reachy-sdk.gitInstall the packages after the cloning.
cd ~/dev/reachy-sdk-apipip3 install -e pythoncd ~/dev/reachy-sdkpip3 install -e .To learn more on the repositories content and usage, please refer to README.md files in each repository.
Other #Install Rust #RUST is needed to enable the communication between the hardware and the ROS packages.
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | shecho \u0026quot;\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho \u0026quot;# RUST\u0026quot; \u0026gt;\u0026gt; ~/.bashrcecho 'source \u0026quot;\$HOME/.cargo/env\u0026quot;' \u0026gt;\u0026gt; ~/.bashrcsource ~/.bashrcOpen ports for serial use #By default, on a Ubuntu install, when using serial, users do not have the right to access the ports. Give rights to open /dev/ttyUSB ports:
sudo usermod -a -G tty \u0026lt;usr_name\u0026gt;sudo usermod -a -G dialout \u0026lt;usr_name\u0026gt;sudo usermod -a -G input \u0026lt;usr_name\u0026gt;Set the correct configuration file #As Reachy software is meant to work with different robot configurations. Several configuration files are available.
By default, the configuration is set to a full robot. You need to modify it to your own configuration.
Open .bashrc:
nano ~/.bashrcAnd add an config file with your model as ~/.reachy.yaml.
For example, to configure only a right arm:
generation: 2023model: right_armzuuu_version: Noneneck_orbita_zero:top: 0.0middle: 0.0bottom: 0.0camera_parameters:left:fx: 0.0fy: 0.0cx: 0.0cy: 0.0k1: 0.0k2: 0.0k3: 0.0p1: 0.0p2: 0.0right:fx: 0.0fy: 0.0cx: 0.0cy: 0.0k1: 0.0k2: 0.0k3: 0.0p1: 0.0p2: 0.0Make sure to source your .bashrc file to take the modification into account:
source ~/.bashrcIf you want to work directly at the ROS level #If you prefer using the ROS2 packages instead of the Python SDK, you can find bring up launch file to set your robot up. In particular, you can run:
ros2 launch reachy_bringup reachy.launch.py If you want to use the SDK, we provide a specific argument that starts everything (including the above mentioned ROS packages) at once:
ros2 launch reachy_bringup reachy.launch.py start_sdk_server:=trueFor more information, check the page Working with ROS2 Humble
Final checking #Everything should now be installed and running on your computer to start working with Reachy! Let\u0026rsquo;s check this out.
💡 Before launching it, the arm should be powered and the USB to serial board connected to your computer. The output in the terminal should look like this:
Especially, you should see the line: SDK ready to be served!.
Finally you can check that you can connect to the arm using Reachy\u0026rsquo;s Python SDK.
In a python terminal:
\u0026gt;\u0026gt;\u0026gt; from reachy_sdk import ReachySDK\u0026gt;\u0026gt;\u0026gt; reachy = ReachySDK(host='localhost')\u0026gt;\u0026gt;\u0026gt;reachyFor a robotic right arm, the outputs should look like this:
If both of these are ok the arm\u0026rsquo;s software installation should have went well!
`}),e.add({id:31,href:"/docs/getting-started/turn-on/",title:"Turn on your robot",description:"Turn on Reachy.",content:`Full/Starter kit #Connect the power supply to the robot (g) placement on the [robot back interface].
Orbita neck needs to start in a straight position for its initialization. To do so, position the head so that Reachy looks straight ahead. (Don’t worry, the position doesn’t need to be exact, it just has to be correctly oriented).
You have two buttons behind the robot:
(a) : turn on/off Reachy’s embedded computer (h) : turn on/off alimentation of Reachy’s motors Arm kit #Plug the power supply on your arm on element (1):
The led should turn red.
Connect directly the the USB2AX board to your computer and you should be good to go! The USB2AX board should be connected with a three wires Dynamixel cable to the power supply board as well.
`}),e.add({id:32,href:"/docs/getting-started/network/",title:"Connect your robot to the network",description:"How to connect your robot to the network.",content:`Hard-wired connection #For Full/Starter kit only:
Use an ethernet cable to connect your robot to the network. The ethernet plug is available at position (b) on [Reachy’s hardware interface].
The computer inside Reachy is configured to use DHCP. It should thus be directly accessible on your network.
WiFi #For Full/Starter kit only:
Reachy is equipped with a Wi-Fi module! You can then directly connect Reachy to your network wirelessly.
Note: if you are connected to Reachy remotely and depending on your use, we advise to favor an ethernet connection to benefit from a more stable connection.
`}),e.add({id:33,href:"/docs/getting-started/mobile-base/",title:"Assemble mobile base + Reachy",description:"Unpack safely and attach your robot correctly.",content:`Assembly tools #You will need hex keys of size 3, 6 and 8 and a screwdriver for the assembly.
Assembly video tutorial #Follow the instructions from the video below to learn how to aasemble the mobile base and Reachy together!
To extract the mobile base from its shipping box, we recommand to remove the wood lid and use the internal handles
Turn on your robot #To power up the robot, release the emergency button and press the mobile base button (next to the mobile base\u0026rsquo;s LCD screen). The mobile base\u0026rsquo;s screen should turn on, indicating the current state of the battery (% remaining, current flow, etc). Then, to power up the arms and head, turn on the switch near its right shoulder. Finally, to turn on the computer, press the button near its left shoulder.
Your browser does not support the video element.
Understanding the power buttons and battery life good practices #The mobile base uses the 24V battery to power the wheels directly. DC-DC converters are used to generate 5V (emergency button power, USB HUB power and relay logic) and 12V for the upper body. The 5V converter draws almost 100mA when idle and is necessary for the emergency button logic.
The emergency button and the mobile base button both need to be ON to turn on the power relay that shares the 24V with the rest of the robot. However, the mobile base button is the only one that, when turned OFF, shuts down the 5V converter.
⚠️ WARNING! ⚠️ When turning off the robot, always turn off the mobile base button to minimize the idle current consumption. If you turn off the robot with the emergency button and didn\u0026rsquo;t press the mobile base button before storing your robot, the battery will deplate faster.
💡 Even with the mobile base button OFF, the battery screen will be powered (low consumption at around ~1mA). If you plan to store the robot for more than a month, we recommend unplugging one of the wires of the battery (like when you received the robot).
Configuration Storage time before depleting a full battery Mobile base button ON, emergency button OFF A few days Mobile base button OFF A few months Unplugging the battery A few years `}),e.add({id:34,href:"/docs/getting-started/dashboard/",title:"Connect to the dashboard",description:"Get an overview of your Reachy's state and access quickly some features with Reachy's dashboard.",content:`We developed a dashboard to give you an overview of the state of your Reachy (which motors are detected, what services are running, what are the motors temperatures\u0026hellip;) as well as giving you the possiblity to access quickly some features (changing a robot\u0026rsquo;s part compliance for example).
This tool has been thought to help you start easier with the robot and facilitate quick debugging.
Follow the instructions on the dashboard first connection page to learn how to connect your Reachy to your wireless network without needing to plug a computer screen, keyboard or mouse.
`}),e.add({id:35,href:"/docs/getting-started/connect/",title:"Connect to your robot",description:"How to connect to your robot.",content:`Connect to the embedded computer #For Full/Starter kit only:
Connect a screen, a mouse and a keyboard to Reachy.
You can also access it via ssh. You will first need to know Reachy’s IP on your network. Then, using your own reachy-ip you can access it via:
ssh reachy@\u0026lt;reachy-ip\u0026gt;Check ROS is providing access to the topics #Open a terminal on the computer, and enter:
ros2 topic listFull/Starter kit topic list #You should see the following list:
/antenna_forward_position_controller/commands/antenna_forward_position_controller/transition_event/diagnostics/dynamic_joint_commands/dynamic_joint_states/forward_fan_controller/commands/forward_fan_controller/transition_event/forward_pid_controller/commands/forward_pid_controller/transition_event/forward_speed_limit_controller/commands/forward_speed_limit_controller/transition_event/forward_torque_controller/commands/forward_torque_controller/transition_event/forward_torque_limit_controller/commands/forward_torque_limit_controller/transition_event/gripper_forward_position_controller/commands/gripper_forward_position_controller/transition_event/grippers/commands/head/averaged_target_pose/head/target_pose/joint_commands/joint_state_broadcaster/transition_event/joint_states/kinematics/transition_event/l_arm/averaged_target_pose/l_arm/target_pose/l_arm_forward_position_controller/commands/l_arm_forward_position_controller/transition_event/left_image/image_raw/compressed/neck_forward_position_controller/commands/neck_forward_position_controller/transition_event/parameter_events/r_arm/averaged_target_pose/r_arm/target_pose/r_arm_forward_position_controller/commands/r_arm_forward_position_controller/transition_event/right_image/image_raw/compressed/robot_description/rosout/tf/tf_staticCheck the topics are correctly updated #On a terminal on the computer, and enter:
ros2 topic echo /joint_statesThe logs correspond to the motors positions in radians. Try to move an arm to check they are correctly updated.
Launch demo programs #In ~/dev/reachy-sdk/notebooks, you can find examples of use for reachy-sdk.
Try them using jupyter:
cd ~/dev/reachy-sdk/notebooksjupyter notebookIf you want to launch the notebooks while connected via ssh:
jupyter notebook --ip=0.0.0.0`}),e.add({id:36,href:"/docs/getting-started/attach/",title:"Attach your robot without a mobile base",description:"Attach your robot correctly.",content:`Full/Starter kit #The first thing to do before using your Reachy Full or Starter kit is to attach it safely.
There are two options to do that:
Using the metal bar included in Reachy\u0026rsquo;s package Attach the metal bar to a table or a flat support using one of the metal fixation and screws:
If you don\u0026rsquo;t want to drill holes in your table, you can also use clamps between the table and the bottom part of the metal bar. However, make sure that the clamps make the attachment well tighten.
Then attach the robot to the metal support rod using the other metal fixation:
A video showing how to install Reachy can be found below. 👇
⚠️ WARNING! ⚠️ Make sure your robot is well attached and the screws tightened enough before beginning to use Reachy.
Note: Do not forget to put the antennas on Reachy’s head!
Putting Reachy on a moveable support You might prefer to have Reachy installed on a support that you can move easily instead of a table. For some applications like mask distribution, having a Reachy attached to a table takes space and was not really convenient for us.
In replacement, we used a rollable TV support along with a custom 3D printed piece to attach the robot to it.
Arm kit #⚠️ WARNING! ⚠️ Make sure your robot is well attached and the screws tightened enough before beginning to use Reachy.
`}),e.add({id:37,href:"/vr/introduction/",title:"VR Introduction",description:"Get quickly introduced to VR teleoperation",content:""}),e.add({id:38,href:"/vr/use-teleop/prepare-robot/",title:"Set Reachy ready",description:"Prepare your robot for teleoperation",content:`To teleoperate Reachy from the same network #If the computer used for the teleoperation app is connected to the same network as your robot, you only need to know your robot IP address.
💡 Don't know how to get it? Find out Reachy's IP address. To teleoperate Reachy remotely #To teleoperate Reachy from another network, you need to create a redirection of an IP address towards your robot local IP address.
Set a static IP address to your robot and use the redirection address on the VR application.
Make sure the robot is ready #For the application to connect to be able to connect to the robot make sure:
the robot is turned on the robot is connected to the network. We advise the robot to be hard-wired using an ethernet cable if the mobile base is not used. all robot services are launched.
By default, all required services are launched automatically when you turn the robot on for full/starter kits. For more information, check the available system services. `}),e.add({id:39,href:"/vr/use-teleop/start/",title:"Teleoperate Reachy",description:"Start and stop Reachy teleoperation using the VR app",content:` 👉🏾 Before starting teleoperating Reachy, please make sure you read the Best Practice In brief #👉 The button names used below are for the Oculus Quest 2. Please refer to the Controllers Input page to get the corresponding names for your device. Start teleoperating Reachy #Make sure the robot is turned on, connected to the network and that all the robot\u0026rsquo;s services are running before launching the teleoperation application.
Select the robot you want to teleoperate (or create a new one), and click on \u0026ldquo;Connect\u0026rdquo;.
Get familiar with the controls in the mirror room and the virtual robot. You may configure various settings here. When you are ready press \u0026ldquo;Ready\u0026rdquo;, and hold (A).
Look straight ahead, with your body in the same orientation as your head while pressing A to start the teleoperation. The initial head position is used to determine the coordinate system giving your VR controllers position.
👉 Warning: you must not move your body anymore after this step. The position of your VR controllers to master the robot arms are calculated depending on the position you had while pressing A. 🚨 Important: even if Reachy is bio-inspired, it cannot reproduce exactly all your movements. There are positions that cannot be reached by the robot. Please avoid unusual movements and do not persist in trying to reach a position if you see that the robot is stuck before it. Come back any time to mirror room by holding A. Teleoperation of the robot is automatically paused if the headset is removed. 👉 Please stop teleoperation before removing your headset (go back to mirror room or quit the app). If you do not, Reachy will continue following your controllers and headset orientation, and this can cause damages to the robot. Stop teleoperation #Come back to the mirror room to pause the teleoperation by holding A at any time during teleoperation.
Leave the app by clicking \u0026ldquo;Quit\u0026rdquo; icons in the mirror room and connection menu.
The motors are automatically turned into compliant mode when quitting the mirror room. Please make sure the arms are close enough to the lowest position they can reach when coming back to the menu to avoid them falling or hitting something.
Step-by-step starting #Make sure that your VR equipement is up and running. Please refer to your device documentation.
Make sure the robot is turned on, connected to the network and that all the robot services are running. By default, if you haven\u0026rsquo;t modified anything, all services should be automatically launched on start of the full/starter kit robots.
Launch the application TeleoperateReachy.exe file if you are using a VR device connected to a Windows computer. For Oculus Quest users, start the app from within the headset if you have installed the .apk.
Equip yourself with your headset, make sure you can see both controllers and that the scene around you is moving correctly in accordance with your head movements.
Choose the robot you want to connect to: you can select a robot with its IP address, or add a new one to the list of available robots.
Press Connect to initiate the communication with the robot. You should be now in the mirror room, and see yourself controlling a virtual reachy. The actual robot is not in control at that time but the live camera stream is displayed at the top right of the mirror. The info, help and settings menus are available here (they are documented in the next section). Please get familiar with the robot controls and features (emotion, grasping lock). When you are ready, face the mirror completely and click on \u0026ldquo;Ready\u0026rdquo;. The position of the actual robot appears in a semi-transparent green color. This may be useful when you\u0026rsquo;ve left the robot in a certain position that you would like to keep when entering the teleoperation. Hold (A) to start the teleoperation. A 3 seconds timer appears while you enter the teleoperation. The motors speeds are reduced during this time to avoid sudden movements of the robot. Full speed is reached at the end of this countdown. 👉 Warning: you don't want to move your torso and body anymore after this step. Only your head and arms. The position of your VR controllers to master the robot arms are calculated depending on the position you had while pressing A. Come back any time to menu by pressing A. Teleoperation of the robot is automatically paused if the headset is removed. Control the mobile base #Use the thumbstick/trackpad to control the mobile base!
The left controller controls the translation of the mobile base, while the right one controls the rotation.
Is there any security to prevent collision with objects?
Yes! If you are too close to a wall or object, the LIDAR anti-collision safety unables the mobile base to go closer to the obstacle. The mobile base will therefore not move in this direction, but you can still go in other directions.
More information on the anti-collision safety
Nevertheless, this security is for the mobile base and won\u0026rsquo;t prevent the robot\u0026rsquo;s arms to collide with external objects, so be aware while teleoperating the robot.
Please note very small objects won\u0026rsquo;t be detected by the LIDAR sensor.
What is the forward direction of Reachy?
The forward direction is aligned with the forward direction of the mobile base, meaning that giving a forward instruction to the robot will always lead the robot to go physically forward, no matter the direction you are looking to.
Check the actual direction of your commands using the indicator at the bottom: the white arrow shows you the direction command relative to your actual head orientation. If your head is correctly aligned with the mobile base forward direction, this arrow will point forward if giving a forward command with your left controller.
In the above images, the same forward command is sent from the left controller.
On the first image, the user is looking straight (the black arrow is located in the target view), so the white mobility arrow is pointing front.
On the second image, the user is looking on the left side (the target view is on the left of the black arrow), so the forward direction is pointing right, as it is the direction aligned with the mobile base forward direction.
Note that these images are only for example, mobility is not available on virtual Reachy.
Use Reachy\u0026rsquo;s emotions #Press (X) (on Oculus Quest 2, check here the input corresponding to your device) when controlling Reachy to open the emotion menu. Use the right thumbstick/trackpad to select the desired emotion icon and release (X). Emotion (movement of antennas) are triggered here. The grasping lock can be also activated from this menu.
Application features #Connection page #\u0026gt; Add a new robot Click on the robot to select to open the panel of all saved robots:
Then click on "Add new robot +" at the bottom right of the page:Enter a robot name and the IP address of the robot (if the headset is connected on a computer, use the computer keyboard), and save your robot card: *The IP address is mandatory. If no name is given to the new robot, it will be called @Reachy by default*\u0026gt; Modify an existing robot Click on the robot to select to open the panel of all saved robots:
Then click on the pencil icon of the robot you want to modify:Modify the info on the robot card and save the card:\u0026gt; Delete a saved robot Click on the robot to select to open the panel of all saved robots:
Then click on the bin icon of the robot you want to delete:Validate the deletion:\u0026gt; Check the gRPC ports Click on \u0026ldquo;Ports information\u0026rdquo; in the connection menu, below the Connect button.
Find there the info of all the gRPC ports used. You can also modify them if you made changes on your robot:Mirror scene #\u0026gt; Check robot status Open the info menu in the mirror room:
The connection and services status, and motor temperature are reported here.\u0026gt; Controller mapping Open the help menu in the mirror room:
The mapping of the controller buttons to the robot actions are displayed here.\u0026gt; Settings menu Open the settings menu in the mirror room:
Here you can set your size to improve the mapping between your movements and reachy's motion. Individual parts of the robot can be deactivated in the case you don't need the mobile base, a specific arm, etc. You can also modify the grasping mode there: with full control you decide at each time the opening of the gripper, while the grasping lock option enables you to close the gripper with on trigger press and open it with another one. Grasping lock option can be turned on/off as well in the emotion menu.\u0026gt; Reset position While facing the mirror, your body should be aligned with Reachy\u0026rsquo;s body. This is mandatory to have a consistent control. If this is not the case after having pressed \u0026ldquo;Ready\u0026rdquo;, face the mirror and click on \u0026ldquo;Reset position\u0026rdquo;.
The "Reset position" button is placed at the bottom of the mirror, under the A loader.Teleoperation exit #\u0026gt; Exit and lock position While press (A) to exit the teleoperation, you may hold (X) to activate the position lock. A lock is displayed when doing so.
The robot will stayed locked while you'll be back in the mirror room. This can be useful to keep a certain position while you need to take a break, change position or remove the headset. The position of the robot will be displayed by the semi-transparent green robot when you will restart the teleoperation.`}),e.add({id:40,href:"/vr/use-teleop/messages/",title:"Teleoperation messages",description:"Understand warning and error messages in the VR teleoperation app",content:`During Reachy teleoperation, several messages can show up in front of view.
Warning messages
Some messages are just warnings, signaling you the quality of teleoperation may be altered or the current state of the robot may evolve into future errors (motors heating up or low battery). These messages are displayed on a dark grey background.
When possible, please consider acting to prevent these warnings from becoming errors.
Error messages
Other messages may signal errors, which will lead to a fast dysfunction of the teleoperation. These messages are to take into account quickly, as you may not be controlling the robot properly anymore when they appear. These messages are displayed on a red background.
👉🏾 When error messages appear, stop teleoperation and act conquently to protect your robot. `}),e.add({id:41,href:"/vr/use-teleop/commands/",title:"Commands",description:"Controller inputs mapping for VR teleoperation",content:`Oculus Quest #Name Feature description A At robot teleoperation start: Start robot teleoperation During teleoperation: Return to menu B During teleoperation: Mobile base boost X During teleoperation: Open emotion menu (keep pressed) / Activate selected emotion (release) When leaving teleoperation (A pressed): Lock robot position Left Thumbstick During teleoperation: Control mobile base translation Right Thumbstick During teleoperation: Control mobile base rotation If emotion menu is open: Select emotion Left Index Trigger In menu: Select button During teleoperation: Control left gripper Right Index Trigger In menu: Select button During teleoperation: Control right gripper Left Controller position / orientation During teleoperation: Reachy\u0026rsquo;s left arm end effector position / orientation Right Controller position / orientation During teleoperation: Reachy\u0026rsquo;s right arm end effector position / orientation Headset orientation During teleoperation: Reachy\u0026rsquo;s head orientation Valve Index #Name Feature description A right At robot teleoperation start: Start robot teleoperation During teleoperation: Return to menu A left During teleoperation: Open emotion menu (keep pressed) / Activate selected emotion (release) When leaving teleoperation (right A pressed): Lock robot position B right During teleoperation: Mobile base boost Left Thumbstick During teleoperation: Control mobile base translation Right Thumbstick During teleoperation: Control mobile base rotation If emotion menu is open: Select emotion Left Index Trigger In menu: Select button During teleoperation: Control left gripper Right Index Trigger In menu: Select button During teleoperation: Control right gripper Left Controller position / orientation During teleoperation: Reachy\u0026rsquo;s left arm end effector position / orientation Right Controller position / orientation During teleoperation: Reachy\u0026rsquo;s right arm end effector position / orientation Headset orientation During teleoperation: Reachy\u0026rsquo;s head orientation HTC Vive #Name Feature description Sandwich menu right At robot teleoperation start: Start robot teleoperation During teleoperation: Return to menu Sandwich menu left During teleoperation: Open emotion menu (keep pressed) / Activate selected emotion (release) When leaving teleoperation (right menu pressed): Lock robot position Left Trackpad During teleoperation: Control mobile base translation Right Trackpad During teleoperation: Control mobile base rotation Center click: Mobile base boost If emotion menu is open: Select emotion Left Index Trigger In menu: Select button During teleoperation: Control left gripper Right Index Trigger In menu: Select button During teleoperation: Control right gripper Left Controller position / orientation During teleoperation: Reachy\u0026rsquo;s left arm end effector position / orientation Right Controller right position / orientation During teleoperation: Reachy\u0026rsquo;s right arm end effector position / orientation Headset orientation During teleoperation: Reachy\u0026rsquo;s head orientation `}),e.add({id:42,href:"/vr/use-teleop/best-practice/",title:"🚨 Best practice",description:"Simple guidelines to follow for a good usage of the VR teleoperation app",content:` 👉🏾 This page contains really important information about the use of the teleoperation app. Please make sure you read it carefully before teleoperating Reachy. Using teleoperation application has nothing complicated, but you need to respect a few guidelines to avoid damaging the robot when using it. This page goes through the main elements you need to keep in mind while teleoperating Reachy. The guidelines are not exhaustive, but should give you a good start on how to safely use the application.
Ideal use of teleoperation #The ideal position to start teleoperation may depend on the surrounding of Reachy. Nevertheless, if the robot environment is compatible with it, we advise to start with the elbows at 90 degrees, lightly away from the torso.
Here is a video of movements and positions that are suitable for teleoperation:Your browser does not support the video element.
Follow all the elements described in the next sections to teleoperate Reachy in the best conditions! All guidelines in video #Watch this quick video to have an overview of the main guidelines to use teleoperation:
The next sections go deeper into each guideline presented in the video and the risks of not following them.Keep the right position #The mapping between your position and the robot is made when holding (A) to start teleoperation. The position and rotation of your headset at this moment are used to calibrate the system. If you move (i.e. change either your body position or orientation), the controllers positions will still be calculated in this coordinate system, and Reachy movements won\u0026rsquo;t look like like yours anymore. For these reasons, you must:
Not move your feet when teleoperating Reachy: they must stay static on the floor. Your browser does not support the video element.
Your browser does not support the video element.
Not rotate your torso. In fact, Reachy\u0026rsquo;s torso won\u0026rsquo;t move, only the arms will try to reach the positions, and this may lead to collision between the Reachy\u0026rsquo;s arms and torso. Your browser does not support the video element.
Your browser does not support the video element.
Avoid movements discontinuities #Reachy doesn\u0026rsquo;t have the exact same degrees of freedom as you have, neither the same range for each joints. When a position cannot be reached, either because of the position or the orientation, the inverse kinematics gives the closest arm configuration found. The closest configuration found for the next position may be:
the same as the previous one, so the arm won\u0026rsquo;t move and you have the impression Reachy is not following your movements anymore quite different from the previous one, which will lead to sudden changes of the arm position All this contribute to give movements that seem incontrollable, due to discontinuities in the arm\u0026rsquo;s inverse kinematics.
To avoid this situation:
Avoid using extreme joints orientations while teleoperating Reachy Avoid unusual arm positions, there are probably above Reachy\u0026rsquo;s joints limits Your browser does not support the video element.
Your browser does not support the video element.
The most limiting joint is the elbow: avoid working to close to your chest, the elbow will be at the limit of its range of motion Your browser does not support the video element.
Your browser does not support the video element.
If the robot seems to stop following your movements, do not continue to move in this direction, you have already reached its workspace limit. Go back to a position you know can be reached. Avoid damaging motors #Reachy\u0026rsquo;s arms have been designed to manipulate objects at a table level and nearby. Some positions away from this nominal area can require a lot of effort from the motors to be maintained, and cause them to overheat fast. Moreover, manipulating objects requires more effort from the motors.
To avoid damaging motors:
Avoid doing movements above your head Avoid keeping your arms straight ahead horizontally to the floor, where the shoulders motors have to carry all the weight of the arms in a static position Your browser does not support the video element.
Your browser does not support the video element.
Do not let the motors in stiff mode when you are in the menu if you are not going to teleoperate the robot soon Do not try to lift objects that are above Reachy\u0026rsquo;s capabilities. If you try to lift an object and see that Reachy\u0026rsquo;s arm can follow your movement or if you head some crackling noise coming from the motors, it probably means that the object is too heavy for Reachy\u0026rsquo;s arm. Your browser does not support the video element.
Your browser does not support the video element.
Avoid damaging 3D parts #Hitting Reachy\u0026rsquo;s arms on objects can break 3D parts of the robot. It may happen even if the arms crash into something at moderate speed.
To avoid damaging 3D parts:
Check the environment surrounding the robot before starting the teleoperation. Make sure you have enough space around the robot and that there is no object to be hit by the robot (this may also save your object from being broken\u0026hellip;) Your browser does not support the video element.
Your browser does not support the video element.
Stop teleoperation close to the position which will be reached when the motors will be compliant, so that the arms won\u0026rsquo;t fall from high. Your browser does not support the video element.
Your browser does not support the video element.
Use teleop safely #Check the environment around you before starting teleoperation. Your browser does not support the video element.
Your browser does not support the video element.
Stop teleoperation before removing your headset! You must be back in the menu before dropping the controllers and removing your headset, because Reachy will continue following your movements until you stop it. Your browser does not support the video element.
Your browser does not support the video element.
Familiarize yourself with the robot #Before teleoperating the actual robot, familiarize yourself with its movements, its workspace and its joints limits. The virtual robot in the mirror scene is a good opportunity for that. Stay near the robot for your first trials: listen to the motors sounds, be aware of your workspace and field of view in a environment you know, try to manipulate light objects. Explore your own workspace with small and quite slow movements to see how the robot reacts and better understand the relation between your movements and its. 💡 You may feel like being in a video game at some point, but never forget that your movements are reproduced in real life! `}),e.add({id:43,href:"/vr/use-teleop/",title:"Use Teleop",description:"How to use the VR application to teleoperate Reachy correctly",content:""}),e.add({id:44,href:"/vr/problem/debug/",title:"Debug",description:"Meeting a problem with teleoperation? Find out what can cause this and how to resolve the situation by yourself",content:`Check the info on the app! #Connect to the robot to get more information on the connection status and the status of the robot. Open the \u0026ldquo;info\u0026rdquo; menu on the left of the mirror.
The connection status give you information about the communication with the robot. Existing connection status are the following:
Connected to a remote Reachy (green): everything seems to be working fine Connected to a remote Reachy. No restart available (yellow): you do not have access to the restart service, but can use normally teleoperation Connected to a remote Reachy. Mobile base unavailable (purple): the configuration of your robot declares a mobile base, but no mobility service is available. You can still teleoperate the robot with no mobility. Trying to connect (blue): the app is looking for the connection with the robot Robot connection failed (orange): you are connected to a remote robot, but either the camera feed or the data stream failed. Teleoperation is not possible Unable to connect to remote server (red): no robot or service is detected after trying to connect You can also check which services are available:
Camera: camera service from the cameras. Mandatory for teleoperation (except for single arm configuration) Joints data: joints services for sending and receiving data from the robot\u0026rsquo;s joints. Mandatory for teleoperation Mobility: services to control the mobile base, available only on robots equipped with a mobile base The app doesn\u0026rsquo;t connect to the robot #If you are not connected to the robot, the reason can be one of the following:
you are not connected to the right IP address the robot is not connected to the network the services are not working on the robot (either not launched or crashed) your computer is not connected to the network the connection is not stable enough for the app to stay connected to the robot Reachy never comes to be ready #First of all, check that the application managed to connect to the robot.
The connection status with the robot is indicated at the top of the mirror. Camera view (top right) is not available if the connection failed.
Connected to the robot Unable to connect to the robot The robot doesn\u0026rsquo;t move properly #Reachy movements are shifted from my real movements
Your head was probably not correctly aligned with your body when you fixed your position, or you moved since the validation step.
Come back to the mirror and validate your choices again to be able to fix a new position.
Reachy movements are jerky
The connection is not fast enough between the robot and your computer, or another program may be alterating the reactivity.
A warning message may also be displayed during teleoperation indicated the network is either unstable or has low speed.
The movements of the robot seem not correlated anymore with mine
If a motor is overheating, it may have stopped working, which can lead in movements looking very different than yours. In reality, the arm is still trying to move according to yours, but the unmoving joints make the configuration of the arm hard to understand.
In most of the cases, an error message should be displayed in the teleoperation, telling that at least 1 motor is in critical error.
Nevertheless it may happen that no error message is displayed, if the motor stopped working before having time to send the information to the teleoperation app: in that case, you received a warning message telling at least 1 motor was heating up previously during teleoperation. Check the temperature of the motors in the Info panel of the transition room.
The mobile base doesn\u0026rsquo;t move #Several elements can make the mobile base unreactive to your inputs.
If you are too close to a wall or object, the LIDAR anti-collision safety unables the mobile base to go closer to the obstacle. The mobile base will therefore not move in this direction, but you can still go in other directions. More information on the anti-collision safety The mobility button has been disabled: to check the status of the mobility button, go in the help panel in the menu (welcome page). Set the mobility to ON. The mobility services are unavailable: check the status of the service in the help panel of the menu. The status of the mobility services is displayed in the info menu. The configuration of your robot does not declare a mobile base, therefore the teleoperation application does not provide any mobility service. Check if a mobile base is expected in the Robot detected configuration section. `}),e.add({id:45,href:"/vr/problem/support-vr/",title:"Support VR",description:"Get support from the community or Pollen Robotics if you meet problems with the VR teleoperation app",content:`FAQ #Check if your question is part of our FAQ.
Forum #Join our Forum if you have any questions, maybe someone has already asked the same question or other people could benefit from the answer!
👉 Any questions relative to your development with Reachy?Go to Pollen Community Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:46,href:"/vr/problem/",title:"Problem",description:"Resolve problems you get using VR teleoperation application",content:""}),e.add({id:47,href:"/vr/introduction/introduction/",title:"Introduction",description:"What is VR teleoperation application?",content:`The Virtual Reality (VR) teleoperation application enables you to control the robot remotely with VR device.
By connecting to your robot, the teleoperation application gives you the ability to move Reachy\u0026rsquo;s arm with the tracking of the VR controllers, to rotate Reachy\u0026rsquo;s head following your own head movements and to see through Reachy\u0026rsquo;s cameras.
You can also manipulate objects remotely controlling Reachy\u0026rsquo;s grippers with your controllers\u0026rsquo; triggers.
Finally, animate Reachy\u0026rsquo;s antennas to share emotions with remote people thanks to predefined antennas movements you can select.
💡 All Reachy 2021/2023 kits (Arm, Starter, Full kit, Full kit + mobile base) can be controlled using the VR teleoperation application, with the functionalities corresponding to the robot configuration. `}),e.add({id:48,href:"/vr/installation/",title:"What needs to be installed",description:"How to install the VR teleoperation application",content:` 👉 Reachy 2021/2023 is already fully compatible with the teleoperation application. You have nothing to install on the robot. ⬇️ Download the latest version of the app On the Oculus Quest 2 #There are two options for this device: use it natively on the headset or run it on your computer using an Oculus link. If you want to use the Oculus Link, please refer to the On Windows computer section. To use it natively, choose one of the following options to install it.
From the Quest Store #Contact us at support@pollen-robotics.com to be added to the list of the beta testers.
Using the apk #Download the apk from our github repo, and install it to your device with your favorite tool (with the meta quest developer hub for instance).
On the Windows computer #Make sure that your VR device is properly installed and running (please refer to your device documentation).
Download the zip archive from our github repo, and unzip it. Simply launch the TeleopReachy.exe file to start the application.
`}),e.add({id:49,href:"/vr/compatibility/pc-requirements/",title:"PC Requirements",description:"Get minimal VR requirements for the teleoperation app to run",content:`The application is built on Unity 2020.3 LTS for which the requirements can be found here.
💡 Note that the app can run natively on Oculus Quest 2. In that case a computer is not required. In order to use the desktop version of the teleoperation application, your PC needs to support Virtual Reality. We recommend the computer to run on Windows, to be powerful enough and equipped with a graphic card.
The computer minimum requirements are the following:
Operating System: Windows 10 (or Windows 7 SP1) Processor: Intel Core i5-4590/AMD FX 8350 equivalent or better Memory: 8GB RAM Graphic card: NVIDIA GeForce GTX 970, AMD Radeon R9 290 equivalent or better Network: Broadband Internet connection. It is highly recommended for your PC to be hard-wired into your router using an ethernet cable. `}),e.add({id:50,href:"/vr/compatibility/headsets/",title:"Headsets",description:"Get the list of compatible VR headset to use the VR teleoperation app",content:`The VR teleoperation application supports any device compatible with Unity 2020.3 including but not limited to the following devices:
Valve Index HTC Vive Oculus Rift Oculus Quest 2 (native or Oculus Link) Please refer to Unity documentation for more information about the compatibility.
`}),e.add({id:51,href:"/vr/compatibility/",title:"Compatibility",description:"Get compatible VR headsets and minimal PC requirements for the teleoperation app to run",content:""}),e.add({id:52,href:"/vr/",title:"VR",description:"Use the VR teleoperation application coming with Reachy",content:""}),e.add({id:53,href:"/help/system/reconnect-motor/",title:"Plugging back a cable of Reachy's arm motor",description:"Reconnect a motor in the arm of the robot.",content:`During manipulation or transportation, a motor cable of Reachy\u0026rsquo;s arm might get disconnected.
An unplugged cable can be spotted more or less easily in each part of an arm, except for the shoulder pitch motor inside Reachy\u0026rsquo;s torso which is a bit harder.
A typical arm of Reachy is composed of eight motors. The motors are connected as a chain starting with the shoulder pitch. Each motor is connected to the motors located before and after it in the chain.
For example in the photo below showing the back of Reachy\u0026rsquo;s wrist, we can see that the wrist roll motor is connected to the wrist pitch motor and to the gripper.
How can I know if a cable is disconnected? #If you can\u0026rsquo;t connect to Reachy using its Python SDK or the VR Teleoperation app\u0026rsquo;, there might be an issue of motor connection.
To check which motors are actually detected, use the discovery tool. It will tell you the motors that the system can see and you would be able to check the missing ones. If one motor is disconnected, the following motors in the arm\u0026rsquo;s chain will not be detected.
For example, if I disconnect the cable between the elbow pitch and the arm yaw motor, Reachy\u0026rsquo;s software will only detect the shoulder pitch, shoulder roll and arm yaw motors in the arm\u0026rsquo;s motors chain.
Thus with the information of the undetected motors you can check if there is any cable disconnected. Just a partial disconnection might be enough to make the motor undetected. You should start by checking the cables of the first missing motor in the chain and run the detection again.
If the motor detection tells you that it sees no motors, there might be just turned off.
How can I reconnect a cable? #Once you spotted the disconnected cable, make sure that you turn off the motors using the interruptor in Reachy\u0026rsquo;s back before starting the reconnection.
Reconnecting a cable should not require strength. If when manipulating you feel that you would need a lot of strength to make the connection between the cable end and the connector, this could be because the cable end and the connector are not well aligned or because the cable end is in the wrong way.
The shoulder pitch cable #The most frequent cable, which is also a hard one to reconnect unfortunately, being disconnected is the cable between the shoulder pitch and the shoulder roll on the side of the shoulder pitch.
You can see the cable on this photo of an arm out of its torso.
Below is a view of the cable from a complete Reachy whose tee shirt has been put down.
We believe that having the images of where this cable is located exactly will help in case you would have to reconnect it.
`}),e.add({id:54,href:"/help/system/reconnect-load-sensor/",title:"Disconnected force sensor",description:"Reconnect the load sensor of the gripper.",content:`TODO: update
Each arm of Reachy is equipped with a load sensor to measure how much force is applied by the gripper to the object. It allows to know when the gripper is holding an object.
The load sensor is in two part: the sensor itself and an electronic board reading its values and connected to Reachy\u0026rsquo;s internal computer.
The sensor is placed between the two 3D printed pieces composing Reachy\u0026rsquo;s gripper.
The electronic board is placed between the gripper and wrist_roll motors of the arms.
The board is connected to Reachy\u0026rsquo;s computer by a long 8 black wires cable plugged by the back.
When we refer in the documentations as the load sensor being disconnected, we refer to the cable between the board and Reachy\u0026rsquo;s computer as disconnected. It\u0026rsquo;s usually the case, the wires between the sensor and the board are rarely desoldered.
You can check an example of the disconnected cable below.
Be aware that there is a way for the connector. On the cable there is a short and a long side.
`}),e.add({id:55,href:"/help/system/manual-focus/",title:"Focus a camera manually",description:"Resolve blurred image with a manual focus.",content:`If for some reason the autofocus implemented in Reachy did not work (due to dust in the lens for example), it is possible to focus the camera by hand. To do that, first connect to Reachy using reachy-sdk:
from reachy_sdk import ReachySDKreachy = ReachySDK('your-reachy-ip-address')Changing the focus with the PythonSDK #Once connected, let\u0026rsquo;s say you want to make the focus of the left camera. You will need to change the focus value by hand. You can have access to it with:
reachy.left_camera.focusThe returned value will be between 0 and 500. You can also set the focus with the same attribute. For example to set the focus to 300:
reachy.left_camera.focus = 300As for the zoom value of the camera, it is between 0 and 600 and can be accessed similarly:
reachy.left_camera.zoomThere is an empirical relationship between the focus value needed to have a clear image and the zoom value of the camera (270 by default). The focus value is inversely proportional with the zoom, meaning that when you set a high zoom value (e.g. 500), the focus value required to have a clear image will be low (between 0 and ~100).
The procedure to make the autofocus by hand is to visualize the image from the left camera and change the focus value at the same time with the PythonSDK until the image looks clear enough. The image from the left camera can be visualized using view_cam_sdk.py:
cd ~/dev/reachy-sdk/reachy_sdk/examplespython3 view_cam_sdk.py left --ip_address='your-reachy-ip-address'(you can exit the window opened by this script by pressing \u0026lsquo;q\u0026rsquo;)
Disabling autofocus at boot #TODO: update ?
Once the focus correctly made, we suggest to remove the autofocus from being done automatically everytime you boot Reachy, if this is not already the case. This is done by commenting the lines 25 to 27 of the file camera_zoom_service.py of reachy_controllers
# for side in ('left', 'right'):# self.controller.homing(side)# self.controller.set_zoom_level(side, default_zoom_level)and line 204 of the same file:
# zoom_controller_service.start_autofocus()Don\u0026rsquo;t forget to rebuild the ROS package so that the changes are taken into account:
cd ~/reachy_wscolcon build --symlink-installsource ~/.bashrc`}),e.add({id:56,href:"/help/system/find-my-ip/",title:"Finding Reachy's IP",description:"Find Reachy IP to connect to the robot remotely, use the SDK or the teleoperation app.",content:`There is a few option to find Reachy\u0026rsquo;s IP. It depends on your setup and how you want to use it.
Checking the LCD display screen in Reachy\u0026rsquo;s back #A small LCD screen should be installed in Reachy’s back to display Reachy’s IP address. You will need to take down its tee-shirt to see the LCD screen.
Working directly on Reachy #You can run the SDK directly on Reachy\u0026rsquo;s computer. In this case, the IP is the localhost address: \u0026ldquo;127.0.0.1\u0026rdquo;.
Via the network #First, you need to make sure that both Reachy and the computer you want to use for the SDK are on the same network. We recommend using an ethernet connection to make sure the latency is as small as possible. It also works on WiFi but for precise and high-frequency control, you should privilege wired option.
We assume you\u0026rsquo;ve already configured the network on Reachy as described in the Setup Reachy section. What you need now is to find Reachy\u0026rsquo;s IP on your network.
ifconfig #If you have access to Reachy directly (by connecting a screen and keyboard), you can run the ifconfig command. The image below show you where to find the IP from the result of the command:
In our case, Reachy\u0026rsquo;s IP is \u0026ldquo;192.168.86.56\u0026rdquo;.
Multicast DNS #If your network and OS support mDNS, you should also be able to connect to Reachy via \u0026ldquo;reachy.local\u0026rdquo;.
Using a smartphone #The Fing app let you scan IPs directly from your smartphone. It also needs to be connected on the same network.
`}),e.add({id:57,href:"/help/system/discovery-tool/",title:"Check which motors are connected",description:"Run the discovery tool and find out any missing element.",content:`Reachy\u0026rsquo;s SDK Server might not work due to a motor that have been disconnected during transportation or manipulation. Knowing which motors are actually detected by Reachy\u0026rsquo;s software is really useful for debug.
Running the discovery #You can run the discovery python script to detect the connected motors.
Make sure that the motors are turned on using the power switch in Reachy\u0026rsquo;s back.
In a terminal, use the command:
reachy-discoveryThis python script will look at each robot\u0026rsquo;s part (e.g head / left arm / right arm for a Reachy full kit or head / right arm for a Reachy starter kit right) and tell which motors it sees. This is useful to check whether there are missing motors, most likely due to a disconnected cable.
Analysing the discovery\u0026rsquo;s output #reachy-discovery will output each motor that has not been detected. There are four types of device that could be missing:
Motors #You might be told that one or multiple motors seem to be missing. Usually it is due to a disconnected cable (it might happen during transportation or manipulation). You can refer to the schematic below to identify where are located the missing motors.
Check the page on How to reconnect a motor if you have any missing motors. For an arm, you should focus on the first motor in the chain missing (the one with the lowest id). Because each motor is connected to the next one sequentially, if one motor is missing, the following in the chain will be as well. For example, if you\u0026rsquo;re being told that the motors l_wrist_pitch (id 25), l_wrist_roll (id 26) and l_gripper (id 27) are missing, it is probably there is a disconnected cable between l_wrist_pitch and the motor before it in the arm\u0026rsquo;s chain i.e. l_forearm_yaw.
Force sensor #There is one force sensor in each Reachy\u0026rsquo;s arm, located between the gripper and wrist_roll motors. The id \u0026lsquo;40\u0026rsquo; is for the left arm\u0026rsquo;s load sensor and the id \u0026lsquo;50\u0026rsquo; is for the one in the right arm.
If you don\u0026rsquo;t see in the discovery a load sensor for an arm, it means that the electronic card used to interact with the force sensor and which is placed around the arm\u0026rsquo;s effector is not detected.
The location of this board is shown below.
Fans board #For each arm, there is a board used to control Reachy\u0026rsquo;s fans called r_fan for the right arm and l_fan for the left arm. If either of them is missing, it means that there might be a connection issue with the card.
Orbita #The last element that you should see if you have a Reachy with an head is the Orbita joint of the neck. If you don\u0026rsquo;t see it, check that the actuator is actually powered, there should be a red led on as shown below.
Redoing a discovery #Doing a new discovery after each cable manipulation for devices will allow you to check if the problem is solved.
💡 Don\u0026rsquo;t forget to turn off and then back on Reachy\u0026rsquo;s motors using the switch in its back before redoing a discovery!
Restarting the service #Once you have all the motors and load sensors you need in the discovery, you can restart Reachy\u0026rsquo;s software.
systemctl restart --user reachy_sdk_server.service`}),e.add({id:58,href:"/help/system/computer-not-running/",title:"Reachy's computer is not running",description:"Resolve computer looking to stay off.",content:`Reachy\u0026rsquo;s computer is off, even after pressing the on button #When you power your robot and turn on both the motors and Reachy\u0026rsquo;s computer, you might have Reachy\u0026rsquo;s computer still not turned on.
There are two ways to check this:
check Reachy\u0026rsquo;s computer power button If the computer is turned on, there should be a round white led around the button brighting.
check if the computer fan is running To do that, first lower Reachy\u0026rsquo;s tee-shirt, on the front side you should see something like this:
The fan is the blue piece on the photo. If you can see the fan blades, it means that the computer is not running. If not, it probably means that the fan is running and it is just too fast for the blades to be seen.
So if you checked that Reachy\u0026rsquo;s computer is off, even after pressing the on button, this probably means that the cable powering it is disconnected.
If it actually is, you should plug the cable back, according to the pin schematic shown in the photo above. This should solve the problem.
Reachy\u0026rsquo;s computer is on, but nothing is displayed #If you can see that Reachy\u0026rsquo;s computer is running (either by seeing the round led in the button brighting or by checking if the computer\u0026rsquo;s fan running) but still can\u0026rsquo;t see any image with a computer screen plugged to the robot, it probably means that there is an issue with the hdmi connection.
First of all, check that that the computer screen is actually powered and that the hdmi cable is well plugged. A defective hdmi cable can also cause bad connections.
💡 You should have the screen already plugged to the computer before starting it. We know that there might be issues when the hdmi cable is plugged the computer being turned on. Sometimes, just restarting the computer solves the problem.
`}),e.add({id:59,href:"/help/system/",title:"System",description:"Resolve most common difficulties and problems with the robot",content:""}),e.add({id:60,href:"/help/debug/support/",title:"Support",description:"Get support for your Reachy robot.",content:`Forum #Join our forum if you have any questions or simply want to take a look at others topics!
👉 Any questions relative to your development with Reachy?Go to Pollen Community Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:61,href:"/help/safety/vr-use/",title:"Use VR teleoperation",description:"Guidelines to use the VR teleoperation app safely, for you, the robot and the surrounding people",content:`Watch all guidelines in video! #Watch this quick video to have an overview of the main guidelines to use teleoperation:
`}),e.add({id:62,href:"/help/safety/correct-use/",title:"Use Reachy properly",description:"Guidelines to use Reachy safely, for you and the robot",content:`Don\u0026rsquo;t harm yourself\u0026hellip; #Even though there is little chance that you get hurt using Reachy, you might get surprised by its movements, especially the first times.
We recommend that you move both Reachy\u0026rsquo;s arms with your hands before you start programming it. The goal is that you get a sense of Reachy\u0026rsquo;s working space, the positions it can reach so that you won\u0026rsquo;t get hit when you actually send it commands.
Your browser does not support the video element.
and don\u0026rsquo;t harm Reachy! #There are a few things you need to know to make sure that your Reachy doesn\u0026rsquo;t get damaged when using it.
Don\u0026rsquo;t stay in stiff mode if you\u0026rsquo;re not moving the robot #Each Reachy\u0026rsquo;s motor can be in one of two compliance modes:
compliant: the motor is soft and can be freely turned by hand as in the video above. It cannot be controlled with code, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motor is hard and cannot be moved by hand. It can be controlled by setting new target position. In this mode, the motor use its maximum torque to maintain its present position until a target position is sent. You should hear a small noise coming from a motor in stiff mode, especially if you try to move it with your hands, it\u0026rsquo;s totally normal. Your browser does not support the video element.
Check out the Python SDK section on how to switch between the two modes.
🚨 What you need to keep in mind #You must be careful not to let the joints in stiff mode when you\u0026rsquo;re not using the robot. This mode can be really demanding for a motor, letting a motor in stiff mode will damage it after some time.
If an arm is lifted or if the neck is lowered, maintaining the position in stiff mode will be exhausting because the motors would have to compensate the gravity and they could get damaged. You can make the analogy with a human. If we ask you to keep stretched out arms, after a certain time it will be painful. So is the case for the joints of the robot.
Be aware of obstacles #When you are sending movements instructions to Reachy, mind the obstacles that could block Reachy during its movements.
For example, when you are asking to an arm to go between two positions, it will try to do it as hard as it can, whether or not there is something on its way. Also when you are moving both arms simultaneously, there are no safety measures implemented to prevent them from hitting each other. Nothing will also prevent Reachy\u0026rsquo;s arms from hitting its chest if you ask them to. If situations like these happen, don\u0026rsquo;t hesitate to use the motor\u0026rsquo;s switch in Reachy\u0026rsquo;s back to immediately turn off the motors so that Reachy\u0026rsquo;s motors will stop trying to reach a position they can\u0026rsquo;t get.
Check the temperatures #Reachy\u0026rsquo;s motors will heat when you are using its joints so you should manage the motors temperatures. The temperatures of each motor can be checked with the dashboard or be accessed using Reachy\u0026rsquo;s Python SDK.
There are two important temperature constants you need to know, their values depend on Reachy\u0026rsquo;s part:
fan trigger temperature: temperature at which the motor will start to get hot and the matching fan should be turned on automatically. The fans allow to work longer with hot joints but enventually the temperature will keep rising if the joints keep being sollicitated. The default value is 45°C on Reachy. shutdown temperature: when this temperature is reached, the motor will normally shutdown and stop working until it has cooled down. This is a precaution measure to protect the motor. The default value is 55°C on Reachy. Even though there exists a shutdown temperature, we recommand that when you intend on using the robot for a long period, you let the arms rest and their motors cool down regularly (5 minutes rest every 30 minutes of effort).
Good practices #Here is a non-exhaustive list of things to remember when you are using your Reachy, in order to make it last as long as possible.
Make sure that the robot is turned off and that the power supply is disconnected when you are not using it. Remember not to let the motors in stiff mode if you don\u0026rsquo;t plan to make them move. Even letting the arms on a table and in stiff mode for quite some time might damage them. Check that no obstacles will be on Reachy\u0026rsquo;s way when it will try to move. Sending commands to Reachy\u0026rsquo;s arms with an obstacle on the way will make the motors force as much as they can. Being in this kind of situation might happen but when this does, remember to turn off the motors immediately using the switch button in Reachy\u0026rsquo;s back. `}),e.add({id:63,href:"/help/safety/",title:"Safety",description:"Use the robot safely in any situation",content:""}),e.add({id:64,href:"/help/debug/faq/",title:"FAQ",description:"FAQ for Reachy's users.",content:`Non exhaustive list of common questions from Reachy\u0026rsquo;s users. If you don\u0026rsquo;t see yours in it, don\u0026rsquo;t hesitate to open a topic on our Forum!
\u0026gt; How to find the IP of my robot? Check the Find my IP section.
\u0026gt; Got \u0026#39;_InactiveRpcError\u0026#39; when I try to use ReachySDK from Python SDK. It\u0026rsquo;s very likely that you have a problem with reachy_sdk_server, the server running Reachy\u0026rsquo;s software. Check the Quick debug section.
\u0026gt; Reachy SDK Server is not running. Check the Quick debug section.
\u0026gt; One of Reachy\u0026#39;s motor red led is blinking This means the motor has overheat and needs to cooldown. Turn the robot off, wait for it to cooldown and turn it on again.
\u0026gt; Reachy\u0026#39;s head doesn\u0026#39;t look straight when asked. You need to start the robot with the head in a position close to straight when starting the robot. Indeed, Orbita\u0026rsquo;s position encoder only covers part of the whole motion range. We use this starting position to recalibrate the absolute position.
\u0026gt; Why can\u0026#39;t Reachy\u0026#39;s computer be turned on? Check the page Reachy\u0026rsquo;s computer is not running explaining why you couldn\u0026rsquo;t have Reachy\u0026rsquo;s computer on.
\u0026gt; How can I view the camera feed? If the SDK server is running, check Reachy\u0026rsquo;s cameras from the Python SDK documentation.
If not, you will need to have a computer screen plugged to Reachy using an HDMI cable. To view the left camera, in a terminal in Reachy\u0026rsquo;s computer:
python3 ~/reachy_ws/src/reachy_2023/camera_controllers/examples/view_cam.py left open_cv\u0026gt; The images from the cameras are blurry. You can use the autofocus available in reachy-sdk. For example, if you want to start the autofocus for the left camera, use:
reachy.left_camera.start_autofocus()If the autofocus did not work, you can learn how to perform the focus manually with this page.
\u0026gt; I connected a computer screen to Reachy, but I can\u0026#39;t see any image. There might be a problem with the HDMI connection or Reachy\u0026rsquo;s computer is actually not turned on. You can check the page Reachy\u0026rsquo;s computer is not running.
\u0026gt; Where can I find examples on how to use the Edge TPU device? Edge TPU Coral device uses the pycroal python library. We use this device everytime we need AI in one of our applications, for example to classify objects for TicTacToe.
\u0026gt; Can you explain a bit Reachy\u0026#39;s software? Check the Overall presentation of the Software section.
\u0026gt; Does Reachy Mobile come with an autonomous navigation stack? The current release does not come with an autonomous navigation stack. However, we have an internal (experimental) version where nav2 runs. If this is of interest to you, please let us know.
`}),e.add({id:65,href:"/help/debug/python-sdk-error/",title:"Quick Debug with the Python SDK",description:"Quick Debug for Reachy's Python SDK.",content:`Problem with Python SDK #If you\u0026rsquo;re using the Python SDK you may encounter the following error when trying to connect to Reachy.
Debugging the SDK server #Verify the service status #If you are using one of the system.d service only:
💡 Note: By default, reachy_sdk_server.service should be running. Open a terminal on the computer, and enter:
systemctl --user status \u0026lt;name_of_the_service\u0026gt;.serviceThe service should indicate ⬤ active (running) as shown below.
If the service is not active, enable it and start it.
systemctl --user enable \u0026lt;name_of_the_service\u0026gt;.servicesystemctl --user start \u0026lt;name_of_the_service\u0026gt;.serviceGet more information on Reachy system.d services here
Checking list #If the service was actually running and the problems still persist, here is a list of things you can look at.
Motors off #This is something we often forget, especially during the first uses of Reachy: turning Reachy\u0026rsquo;s motors on using the power switch in Reachy\u0026rsquo;s back before turning on Reachy\u0026rsquo;s computer.
Respecting this order of ignition is needed for the sdk server to start correctly.
Reachy\u0026rsquo;s computer is off #If you work only remotely on Reachy, you may have forgotten to turn Reachy\u0026rsquo;s computer on using the round button in the back. A round white led around the button should be on when the computer is on.
If you\u0026rsquo;re having trouble turning on Reachy\u0026rsquo;s computer, you can check the page on why Reachy\u0026rsquo;s computer is not running.
Using an incorrect IP address #If you work on Reachy remotely, you might have entered the wrong IP address when you were trying to connect to the robot using ReachySDK(host=\u0026lsquo;Reachy IP address\u0026rsquo;). Check the section on how to find Reachy\u0026rsquo;s IP address.
One motor is disconnected #The cable of one of Reachy\u0026rsquo;s motor might be disconnected. To check that, you can use the discovery tool to check if all the motors are detected.
If one motor is disconnected, check the page on How to reconnect a motor.
Force sensor not detected #Reachy is equipped with a force sensor in each gripper connected to Reachy\u0026rsquo;s computer by an eight wires cable which may have been disconnected during manipulation or transportation. The discovery tool can also indicate if Reachy\u0026rsquo;s software detects the force sensors.
If one force sensor is disconnected, check the page on how to reconnect a load sensor.
Camera opening failed #Sometimes, Reachy\u0026rsquo;s cameras cannot be accessed correctly by Reachy\u0026rsquo;s computer. With a computer screen connected to Reachy\u0026rsquo;s back using an HDMI cable, you can check whether the camera reading is working or not.
A python script is available to view the camera feed. In a terminal in Reachy\u0026rsquo;s computer:
\$ systemctl --user stop reachy_sdk_server.service\$ python3 ~/reachy_ws/src/reachy_2023/camera_controllers/examples/view_cam.py left opencvIf a window opens with the camera feed: great, the left camera is correctly detected. You can press \u0026lsquo;q\u0026rsquo; to exit the window.
Same for the right camera:
\$ python3 ~/reachy_ws/src/reachy_2023/camera_controllers/examples/view_cam.py right opencvIf one (or both) of them is not working, you can check if the USB cable coming from Reachy\u0026rsquo;s neck is correctly connected.
If it was actually connected, usually restarting Reachy\u0026rsquo;s computer does the trick.
Checking if the problem is solved #If you think you were in one of situations above and you solved it, you can restart Reachy\u0026rsquo;s server and try to reconnect to Reachy.
In a terminal:
\$ systemctl --user restart reachy_sdk_server.serviceIn a Python terminal:
from reachy_sdk import ReachySDKreachy = ReachySDK(host='localhost')You should not have the _InactiveRpcError again after the second instruction if the server is working well.
Nothing worked! #If none of the above worked, you can launch Reachy\u0026rsquo;s server by hand. This is the best way to know what is wrong as it will print everything. However, there might be a lot of information so it can be quite hard to interpret.
\$ systemctl --user stop reachy_sdk_server.service\$ bash ~/reachy_ws/src/reachy_2023/reachy_sdk_server/launch.bashDon\u0026rsquo;t hesitate to put the output of launch.bash in a new topic of our forum, a team member of Pollen will help you debug it.
`}),e.add({id:66,href:"/help/debug/check-dashboard/",title:"Check the dashboard",description:"Use the dashboard to check Reachy's status and debug Reachy's issues and start applications.",content:`The dashboard\u0026rsquo;s debug page will indicate you basic debug info like if one of Reachy\u0026rsquo;s motor or force sensor is disconnected or if you forgot to turn on Reachy\u0026rsquo;s motors before booting its computer.
You can also check the status of reachy_sdk_server.service in the dashboard\u0026rsquo;s services page using the dashboard\u0026rsquo;s services page to get error messages.
Access the dashboard #From the robot:
Access the dashboard at 127.0.0.1:3972
From any other device on the same network as the robot:
Access the dashboard at \u0026lt;robot-ip\u0026gt;:3972
`}),e.add({id:67,href:"/help/",title:"Help",description:"Get help and support for Reachy.",content:""}),e.add({id:68,href:"/sdk/mobile-base/safety/",title:"Anti-collision safety",description:"LIDAR based anti-collision behaviour for the mobile base.",content:`Overview #The basic idea is that the LIDAR is used to detect surrounding obstacles and reduce or nullify speed commands that would create a collision with the mobile base.
Your browser does not support the video element.
The safety is active regardless of how you command the mobile base (teleop, controller, goto and set_speed).
⚠️ The safety only works with obstacles that can be seen by the LIDAR. Small obstacles that are below the LIDAR won\u0026rsquo;t be seen. Similarly, the LIDAR will see the legs of a table, but not the table top.
💡 We recommend that you get a feel of how this safety works by moving around with the controller see (getting started). Drive slowly into a wall, the mobile base should slow down and then stop. The safety should prevent the collision even when driving into the wall at full speed, which we do not recommend though :).
Detailed behaviour #Your browser does not support the video element.
If an obstacle is present inside of the critical distance boundary, then the speed of the mobile base is reduced in all directions, and nullified in the direction that would cause a collision. Rotations are slowed down but are still allowed. Otherwise, if an obstacle is present inside of the safety distance boundary, then the speed of the mobile base is reduced only in the directions that would eventually cause a collision. Rotations are unchanged. Obstacles that are further away than the safety distance do not trigger the safety in any way 💡 Reachy\u0026rsquo;s design allows the LIDAR to see close to 360° around it, but not entirely because of the metal bar: this creates a small blind spot. Even if a collision would be very unlikely (you\u0026rsquo;d have to e.g. drive backwards onto a perfectly aligned pole), any speed command that could create an unseen collision are slowed down.
⚠️ Do not obstruct the LIDAR by placing an objet on top of the mobile base as it will be considered as an obstacle.
⚠️ If the LIDAR disconnects during usage or if its controller crashes, then the mobile base will stop and will reject commands.
Advanced tuning #The mobile base\u0026rsquo;s Hardware Abstraction Layer runs with the anti-collision behaviour active by default. Currently, disabling/enabling the safety is the only configuration you can make using the SDK. If you need to fine tune the behaviour, you\u0026rsquo;ll have to interact with the world of ROS and change the HAL parameters (you\u0026rsquo;ll have to recompile the package for the changes to take effect).
The code can be accessed here.
`}),e.add({id:69,href:"/sdk/mobile-base/moving-the-base/",title:"Moving the mobile base",description:"Presentation of the different functions available to make the mobile base move",content:`Frame conventions #REP 105 “Coordinate Frames for Mobile Platforms” #Our design is coherent with ROS\u0026rsquo; conventions described in REP 105 “Coordinate Frames for Mobile Platforms”
Robot frame #The robot frame or egocentric frame or base_link frame is rigidly attached to the robot. Its (0, 0) point is the projection on the floor of the center of the mobile base. X in front, Y to the left, Theta positive counterclockwise.
Odom frame #The odom frame is a world-fixed frame. The position (x, y, theta) of the robot in the odom frame is continuously updated by the HAL through odometry calculations. These calculations currently only use the measurements from the wheels to estimate the movement of the robot. While the position of the robot is continuous, it should never be relied upon for long-term reference as it will always drift.
The initial position of the odom frame matches the position of the robot when the HAL was started. The odom frame can also be reset to the current position of the robot using:
reachy_mobile.mobile_base.reset_odometry()Moving the mobile base #There are two interfaces in the SDK to control the mobile base: spamming speed commands or setting a goal position in the odom frame.
Using the set_speed method #Since the mobile base is holonomic, the set_speed method expects 3 speed commands expressed in the robot frame:
x_vel, in m/s. The instantaneous speed positive in front of the robot. y_vel, in m/s. The instantaneous speed positive to the left of the robot. rot_vel, in deg/s. The instantaneous rotational speed positive counterclockwise. See the joy_controller code for a working example.
💡 As a safety measure, the HAL will stop the wheels if it didn\u0026rsquo;t receive a new goal speed in the last 200ms.
💡 The way this is implemented in the HAL is simply to listen to the /cmd_vel topic, apply some smoothing, perform the kinematic calculations and send the speed commands to the wheels. This makes it very easy to create control interfaces using ROS, see the keyboard example or the joy controller example.
Note: the HAL has a drive mode to set speed commands for variable amounts of time. Instead of relying on a topic, it creates a service. The niche usage didn\u0026rsquo;t warrant the added complexity, so the interface with the SDK was not made. But if needed, it exists!
Using the goto method #The goto method expects a goal position in the odom frame, composed of 3 elements: x in m, y in m and theta in deg.
⚠️ The most important thing to get used to, is the fact that the odom frame is world-fixed and that the position of the robot is always updated as long as the HAL is running (the HAL is automatically started during the robot boot-up). So by default, if you ask for a goto(0, 0, 0) the robot will try to comeback to the position it was at boot-up.
To perform a goto relative to the current position of the robot, use the method reset_odometry(). For example, create an instance of reachy with:
from reachy_sdk import ReachySDKreachy_mobile = ReachySDK(host='your-reachy-ip', with_mobile_base=True)Reset the odometry frame, and ask the robot to move 50cm in front of it:
reachy_mobile.mobile_base.reset_odometry()reachy_mobile.mobile_base.goto(x=0.5, y=0.0, theta=0.0)Now, ask for a goto(0,0,0). The robot should go back to its previous position:
reachy_mobile.mobile_base.goto(x=0.0, y=0.0, theta=0.0)We recommend taking the time to play around with this concept. You can use this Jupyer notebook to explore the goto method.
By default, the robot will always try to reach the goal position, meaning that even if the robot did reach its position and you push it, it will try to come back to the the goal position again.
However, you can define two types of stop conditions through optional parameters (see the above Jupyter notebook for a working example).
A timeout, expressed in seconds. The robot stops the goto when the elapsed time since the start of the command is superior to the timeout. There is a default timeout that scales with the distance asked by the goto. A spatial tolerance, expressed with 4 values: delta_x (the error in m along the X axis), delta_y (the error in m along the Y axis), delta_theta (the angle error in deg) and distance (the l2 distance between the current position and the goal position in m). The robot stops the goto when it is close enough to satisfy all 4 conditions simultaneously. explored in : 💡 Note: the goto behaviour is implemented in the HAL using 3 independent PIDs, one to reduce delta_x, one for delta_y and one for delta_theta. The PIDs can\u0026rsquo;t be tuned at the SDK level, but they can at the HAL level.
`}),e.add({id:70,href:"/sdk/mobile-base/mobile-base-alone/",title:"Using the mobile base without Reachy",description:"How to use the mobile base without a Reachy",content:`There is no need to instanciate the entire Reachy stack to interact with the mobile base. Instanciating the mobile-base-sdk alone is very fast and easy:
from mobile_base_sdk import MobileBaseSDKmobile_base = MobileBaseSDK('your-reachy-ip')This will work even if the upper body is not powered (the computer has to be powered though).
Once the object \u0026lsquo;mobile_base\u0026rsquo; is implemented the syntax is the same to what has been covered in the rest of the documentation, just remove the \u0026ldquo;reachy.\u0026rdquo; keyword. For example, to read the odometry just type:
mobile_base.odometryYou can use this Jupyter Notebook example to test this.
`}),e.add({id:71,href:"/sdk/mobile-base/getting-started/",title:"Getting started with the mobile base",description:"Quick overview of the mobile base control using the Python SDK",content:`Overview #To control the mobile base, we developed a Python SDK working similarly to reachy-sdk but only for the mobile base: mobile-base-sdk. As with reachy-sdk, you can use mobile-base-sdk to connect to the base remotely from another computer, as long as your computer and Reachy\u0026rsquo;s computer are connected to the same network.
However, to avoid having to use two different Python SDks when working on Reachy mobile, we integrated the use of mobile-base-sdk in reachy-sdk so that when you\u0026rsquo;re accessing the mobile base with the reachy_mobile.mobile_base attribute, you are actually using mobile-base-sdk.
Having a dedicated SDK for the mobile base still gives the advantage of having the possibility to work on the mobile base alone. More detailed in the page Using the mobile base without Reachy.
Installation #If you did not do it yet, follow the instructions from the install page to learn how to install Reachy\u0026rsquo;s Python SDK on your computer. We recommend performing the installation in a virtual environment.
💡 You will need to make sure that you get a version of reachy-sdk \u0026gt; 0.5.1 to be able to connect to the mobile base.
Even though you used PyPi for the installation, we recommend cloning the mobile-base-sdk repository on your computer as it gives you access to many examples to learn how to use the mobile base.
Connecting to Reachy mobile #Connecting to the mobile base using Reachy\u0026rsquo;s Python SDK is as simple as connecting to Reachy. When instanciating the ReachySDK object with your Reachy\u0026rsquo;s IP as in the Hello World page, you just have to specify that you are using a mobile base.
from reachy_sdk import ReachySDKreachy_mobile = ReachySDK(host='your-reachy-ip', with_mobile_base=True)The mobile base is then accessible with the reachy_mobile.mobile_base attribute.
reachy_mobile.mobile_base\u0026gt;\u0026gt;\u0026gt; \u0026lt;MobileBase host='your-reachy-ip' - version=1.0 - battery_voltage=29.1 - drive mode=cmd_vel - control mode=open_loop\u0026gt;What is accessible on the mobile base #The following are accessible with reachy_mobile.mobile_base:
mobile base version, battery level, odometry of the base, control and drive modes, goto and set_speed methods to make the mobile base move. The section moving the mobile base details the use of the goto and set_speed methods, the odometry of the base while the advanced section explains the role of the control and drive modes.
Moving the mobile base #Using the goto method #You can move the base with just one line of code, using the goto method. For example, you can make a 90 degrees rotation:
reachy_mobile.mobile_base.reset_odometry()reachy_mobile.mobile_base.goto(x=0.0, y=0.0, theta=90.0)Okay, that was 2 lines of code, but the first one is not needed and was added for safety. The section moving the mobile base is dedicated to explaining how to move the base using the Python SDK.
Check the getting-started notebook for a detailed getting started example using the Python SDK.
Using a joystick #The best (and easiest) way to get a sense of how the mobile base moves is by moving it yourself! It is easy to do that with the joy_controller.py script where you can fully control the mobile base using an Xbox or PlayStation joystick (a controller should be included with your Reachy mobile).
To start controlling the base with joy_controller.py, just type:
cd ~/dev/mobile-base-sdk/examples/scriptpython3 joy_controller.pyThe left joystick will be used for translation and the right one for rotation.
Your browser does not support the video element.
The script reads the controller and uses the mobile-base-sdk to send speed commands to the mobile base. Don\u0026rsquo;t hesitate to take a look at the code to have an example of good practices for an app involving the base.
Hardware Abstraction Layer #In this documentation, you\u0026rsquo;ll find references to the Hardware Abstraction Layer (HAL). The HAL is the ROS2 middleware that interacts with the hardware while the SDK interacts with the HAL. This modular software architecture allows for more flexibility and a simple, high level interface. However, if you need more control or a feature that wasn\u0026rsquo;t ported to the SDK, you can interact directly with the HAL. The philosophy behind this documentation is to give an easy access to the most common usages, and to give pointers that can be useful when pursuing a more advanced usage. The HAL repository can be found here.
`}),e.add({id:72,href:"/sdk/mobile-base/drive-control-modes/",title:"Advanced",description:"Drive modes and control modes description for the mobile base.",content:`Drive modes #Overview #The drive mode impacts the way the mobile base accepts commands. We could say it\u0026rsquo;s the current state of the mobile base.
In most cases, there is no need to think about these modes or to handle them in your code. Below are the most common use cases.
If you want to use the set_speed method to spam speed commands (e.g. pilot the robot with a controller), the mode has to be manually changed to \u0026lsquo;cmd_vel\u0026rsquo;: reachy_mobile.mobile_base.drive_mode = 'cmd_vel'If you want to push the robot easily, this will set the wheels in a compliancy state: reachy_mobile.mobile_base.drive_mode = 'free_wheel'On the contrary, if you want the robot to apply a passive resistance to movement, use: reachy_mobile.mobile_base.drive_mode = 'brake'You can use this Jupyter Notebook to explore the drive modes with your mobile base.
Detailed behaviour #This section is only useful if you intend to interact directly with the Hardware Abstraction Layer (HAL).
Six drive modes are available for the mobile base:
cmd_vel: in this mode, speed instructions can be spammed to the wheels controllers. This mode is used for the set_speed method. brake: in this mode, the wheels will be stiff. free_wheel: in this mode, the wheels will be as compliant as possible. emergency_stop: in this mode, the wheels will stop receiving mobility commands. Switching to this mode will also stop the mobile base hal code. This is a safety mode. speed: another mode to send speed instructions, but less frequently than with the cmd_vel mode. This mode is actually not used at this level (python SDK level), but is implemented at the ROS level, in case one might need it. goto: this mode is used for the goto method. note: the \u0026lsquo;speed\u0026rsquo; and \u0026lsquo;goto\u0026rsquo; modes can\u0026rsquo;t be changed by hand. The drive mode is handled automagically when requesting a set_speed or a goto.
The code for the HAL can be found here
Control modes #Overview #The control mode dictates the low level control strategy used by the mobile bases\u0026rsquo;s HAL.
Two control modes are possible:
open_loop (default mode): in this mode, the wheels are compliant and the control is smoother.
reachy_mobile.mobile_base.control_mode = 'open_loop'pid: in this mode, the wheels are stiff and the control is more precise.
reachy_mobile.mobile_base.control_mode = 'pid'💡 We recommend that you run the following Jupyter Notebook to get a feel of what the control mode does.
Detailed behaviour #Regardless of how the mobile base is piloted (goto, set_speed, controller), the HAL always ends up calculating a goal rotational speed for each wheel. The control mode only changes the used strategy to reach that rotational speed.
In the open_loop mode, a simple affine model was identified to match a PWM to a goal rotational speed. The VESC controllers then apply the PWM directly to the motors of the wheels, without any other low level control. The measures can be found here. While the model is simple, it does account for the static friction and the experimental data shows a good fit when the mobile base is on a flat surface. In the pid mode, the HAL gives the goal rotational speeds directly to the VESC controllers of each wheel. The VESC will use a PID controller to control the speeds. `}),e.add({id:73,href:"/advanced/",title:"Description",description:"Reachy's description.",content:""}),e.add({id:74,href:"/sdk/getting-started/introduction/",title:"Introduction",description:"Introduction to the Python SDK.",content:`The SDK in a nutshell #The Python SDK lets you easily control and program a Reachy robot. It is used to read sensor information (eg. force sensor, camera image or joint position) and send actuator commands (eg. target position, turning on a fan).
It is designed to:
let you start controlling your robot in a few lines of codes, allow to focus on your application and not on hardware synchronisation issues, facilitate fast prototyping and iteration. Connecting to your robot and getting the up-to-date position of all joints is as simple as:
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPfor name, joint in reachy.joints.items():print(f'Joint \u0026quot;{name}\u0026quot; position is {joint.present_position} degree.')You can use it directly on Reachy\u0026rsquo;s computer or work remotely on another computer, as long as you are connected on the same network. The SDK works on Windows/Mac/Linux and requires Python \u0026gt;= 3.6. It is entirely open-source and released under an Apache 2.0 License.
Is this the right option for me? #The Python SDK is only one way to control Reachy. There are other options that have different pros and cons.
To know if the SDK is the right option, the TL;DR here would be something like:
You want to focus on creating an application or behavior on Reachy. You don\u0026rsquo;t want to dig into the details on how it can be controlled or run very time constrained code (eg. need more than 100Hz control). You have basic knowledge of Python (no advanced knowledge is required). You do not already have an important code base running on ROS2. The other options #Unity VR App #If you are interested in tele-operation and want to control Reachy via VR controllers, you can directly use our Unity VR App. More information on the [dedicated section].
ROS2 Humble packages #Reachy runs on ROS2 Humble. ROS is a Robotic Operating System, it offers a huge variety of compatible algorithms and hardware drivers. Yet, if you are not familiar with ROS, the beginning can be a bit overwhelming.
The embedded NUC computer comes with ROS2 and Reachy specific packages already installed and running. They provide full access to Reachy (lower-level than the SDK). You can:
get the joint states and forward position controllers use Rviz subscribe to various sensor topic (camera, force sensor, etc) access client for IK/FK For more information, please refer to the [dedicated section].
Custom gRPC client #If you want to use another language than Python, for instance to integrate Reachy\u0026rsquo;s control within an existing code base, you can write your own gRPC client. Our API is available here.
The API is used both by the Python SDK and the VR App.
`}),e.add({id:75,href:"/sdk/getting-started/install/",title:"Installation",description:"How to install the Python SDK, either from PyPi or directly from sources.",content:`How to install the Python SDK #The Python SDK is a pure Python library. The installation should thus be rather straightforward. It supports Python \u0026gt;= 3.6 (older versions may work but are not officially supported). It works on Windows/Mac/Linux.
⚠️ SDK versions prior to 0.7.0 are incompatible with Reachy 2023.
We recommend to use virtual environment for your development. They make the installation simple and avoid compatibility issues. They also come with their pip command.
From PyPi #pip3 install reachy-sdkFrom the source #git clone https://github.com/pollen-robotics/reachy-sdkpip3 install -e reachy-sdkDependencies #The SDK relies on a few third-party Python packages:
numpy - mostly for trajectory computation opencv - for camera frame access grpc - to connect to the robot They will be installed automatically when you install the SDK.
`}),e.add({id:76,href:"/sdk/getting-started/hello-world/",title:"Hello World",description:"First SDK connection with your Reachy",content:`Now you should be able to connect to your Reachy and check that everything is ok. As we spoiled in the previous section, to connect to your robot, you simply need to run the following code:
from reachy_sdk import ReachySDK# Replace with the actual IP you've found.reachy = ReachySDK(host='the.reachy.ip.found.')Before diving into the next chapters that will guide you in the depth of what you can do with the Reachy SDK, here is a quick preview.
Getting joints state #To make sure everything is working fine, let\u0026rsquo;s check the position of its joints. We won\u0026rsquo;t go into details here as we will detail everything later.
To get the state of a joint, you can access the joints attribute that contains all joints and iterate over its content:
for name, joint in reachy.joints.items(): print(f'Joint \u0026quot;{name}\u0026quot; is at pos {joint.present_position} degree.') Will show something like:
Joint \u0026quot;l_shoulder_pitch\u0026quot; is at pos -3.6 degree.Joint \u0026quot;l_shoulder_roll\u0026quot; is at pos 1.5 degree.Joint \u0026quot;l_arm_yaw\u0026quot; is at pos -3.1 degree.Joint \u0026quot;l_elbow_pitch\u0026quot; is at pos 2.0 degree.Joint \u0026quot;l_forearm_yaw\u0026quot; is at pos -54.4 degree.Joint \u0026quot;l_wrist_pitch\u0026quot; is at pos -0.9 degree.Joint \u0026quot;l_wrist_roll\u0026quot; is at pos -20.7 degree.Joint \u0026quot;l_gripper\u0026quot; is at pos 43.0 degree.Joint \u0026quot;r_shoulder_pitch\u0026quot; is at pos 0.8 degree.Joint \u0026quot;r_shoulder_roll\u0026quot; is at pos 0.5 degree.Joint \u0026quot;r_arm_yaw\u0026quot; is at pos 1.2 degree.Joint \u0026quot;r_elbow_pitch\u0026quot; is at pos 0.1 degree.Joint \u0026quot;r_forearm_yaw\u0026quot; is at pos 0.1 degree.Joint \u0026quot;r_wrist_pitch\u0026quot; is at pos 1.1 degree.Joint \u0026quot;r_wrist_roll\u0026quot; is at pos 4.5 degree.Joint \u0026quot;r_gripper\u0026quot; is at pos -0.7 degree.Joint \u0026quot;l_antenna\u0026quot; is at pos -1.9 degree.Joint \u0026quot;r_antenna\u0026quot; is at pos -3.7 degree.Joint \u0026quot;neck_roll\u0026quot; is at pos -20.1 degree.Joint \u0026quot;neck_pitch\u0026quot; is at pos -14.1 degree.Joint \u0026quot;neck_yaw\u0026quot; is at pos -48.0 degree.Note that we have accessed the attribute present_position to get the joint actual position. You can access the position of a specific joint by using its full name (meaning the part it is attached to plus its name). For instance, to get the position of the \u0026rsquo;left shoulder pitch':
\u0026gt;\u0026gt;\u0026gt; print(reachy.l_arm.l_shoulder_pitch.present_position)-3.6You can also get a resume of the joint state by doing:
\u0026gt;\u0026gt;\u0026gt; print(reachy.l_arm.l_shoulder_pitch)\u0026lt;Joint name=\u0026quot;l_shoulder_pitch\u0026quot; pos=\u0026quot;-3.58\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;If you did not run anything else, your robot should be compliant (meaning you can freely move it). You can try to move it and re-run the code above. You should see that without doing anything specific, the positions are automatically updated.
Seeing what Reachy sees #Assuming, you are still connected (otherwise, simply reconnect), we will now display what Reachy sees as an OpenCV window.
import cv2 as cvwhile True:# This let you access the last frame grabbed by Reachy left eye# It's always the most up-to-date imageleft_image = reachy.left_camera.last_framecv.imshow('left image', left_image)cv.waitKey(30)You should now see what Reachy sees!
To stop the code, press Ctrl-C.
`}),e.add({id:77,href:"/sdk/getting-started/finding-ip/",title:"Finding Reachy's IP",description:"Find Reachy's IP address to connect to it.",content:`The last required step before actually programing your Reachy is to find its IP address.
A small LCD screen should be installed in Reachy\u0026rsquo;s back to display Reachy\u0026rsquo;s IP address. You will need to take down its tee-shirt to see the LCD screen.
The instructions to display the IP address to the LCD screen is provided by the dashboard which is started at boot with the service reachy_dashboard.service.
If the LCD screen is not working, check out the page Find my IP section to learn other ways to get the IP address.
Note: Using the SDK locally also avoids network potential latency or bandwidth issue. Yet, it may not be as convenient as working directly from your usual laptop. You need to plug a screen, keyboard and mouse directly on Reachy\u0026rsquo;s computer.
You can check that everything is working as expected by running the following Python code:
from reachy_sdk import ReachySDK# Replace with the actual IP you've found.reachy = ReachySDK(host='the.reachy.ip.found.')`}),e.add({id:78,href:"/sdk/mobile-base/",title:"Mobile Base",description:"Learn how to use Reachy's mobile base.",content:""}),e.add({id:79,href:"/sdk/getting-started/",title:"Getting Started",description:"Getting Started with the SDK.",content:""}),e.add({id:80,href:"/sdk/first-moves/safety/",title:"Safety first",description:"What you need to be aware of as a user to prevent Reachy from getting damaged and you from getting hurt while working with the Python SDK.",content:`First, make sure that you followed the instructions from the section detailing how to attach your robot.
Especially, the screws in the Reachy\u0026rsquo;s back and the ones fixatings its metal support should be well tightened.
Turning on/off the motors #If at anytime when you\u0026rsquo;re working with Reachy you feel that you\u0026rsquo;re losing control of the robot\u0026rsquo;s movements, don\u0026rsquo;t hesitate to turn the motors off. Use the switch button placed in its back.
Also, don\u0026rsquo;t forget to turn the motors off when you\u0026rsquo;re done working with the robot.
Don\u0026rsquo;t harm yourself\u0026hellip; #Even though there is little chance that you get hurt using Reachy, you might get surprised by its movements, especially the first times.
We recommend that you move both Reachy\u0026rsquo;s arms with your hands before you start programing it. The goal is that you get a sense of Reachy\u0026rsquo;s working space, the positions it can reach so that you won\u0026rsquo;t get hit when you actually send it commands.
and don\u0026rsquo;t harm Reachy! #There are a few things you need to know to make sure that your Reachy doesn\u0026rsquo;t get damaged when using it.
Don\u0026rsquo;t stay in stiff mode if you\u0026rsquo;re not moving the robot #Each Reachy\u0026rsquo;s motor can be in one of two compliance modes:
compliant: the motor is soft and can be freely turned by hand. It cannot be controlled, setting a new target position will have no effect. Yet you can still read the motor position. stiff: the motor is hard and cannot be moved by hand. It can be controlled by setting new target position. In this mode, the motor use its maximum torque to maintain its present position until a target position is sent. You can change the compliance mode of a joint with its compliant attribute.
reachy.r_arm.r_gripper.compliant = False # stiff modereachy.r_arm.r_gripper.compliant = True # compliant modeor if you prefer to change the compliance of all the joints in a part of Reachy (left/right arm or the head), you can use the turn_on() and turn_off() methods.
turn_on() puts all the joints of the requested part in stiff mode whereas turn_off() put them in compliant mode.
reachy.turn_on('r_arm')Try this on your robot to feel the resistance applied by the right arm\u0026rsquo;s motors in stiff mode. You can compare with the left arm which should be in compliant mode. You should hear a small noise coming from the right arm\u0026rsquo;s motors, especially if you try to move them with your hands, it\u0026rsquo;s totally normal when they are in stiff mode.
If you want to the right arm\u0026rsquo;s motors back to compliant mode:
reachy.turn_off('r_arm')What you need to keep in mind #You must be careful not to let the joints in stiff mode when you\u0026rsquo;re not using the robot. This mode can be really demanding for a motor, letting a motor in stiff mode will damage it after some time.
If an arm is lifted or if the neck is lowered, maintaining the position in stiff mode will be exhausting because the motors would have to compensate the gravity and they could get damaged. You can make the analogy with a human. If we ask you to keep stretched out arms, after a certain time it will be painful. So is the case for the joints of the robot.
Be aware of obstacles #When you are sending movements instructions to Reachy, be careful to obstacles that you could block Reachy during its movements.
For example, when you are asking to an arm to go between two positions, it will try to do it as hard as it can, whether or not there is something on its way. Also when you are moving both arms simultaneously, there are no safety measures implemented to prevent them from hitting each other. Nothing will also prevent Reachy\u0026rsquo;s arms from hitting its chest if you ask them to. If situations like these happen, don\u0026rsquo;t hesitate to turn off the motors so that Reachy\u0026rsquo;s motors will stop trying to reach a position they can\u0026rsquo;t get.
Check the temperatures #Reachy\u0026rsquo;s motors will heat when you are using its joints so you should manage the motors temperatures. The temperatures of each motor can be checked with the dashboard or be accessed using Reachy\u0026rsquo;s Python SDK.
There are two important temperature constants you need to know, their values depend on Reachy\u0026rsquo;s part:
fan trigger temperature: temperature at which the motor will start to get hot and the matching fan should be turned on automatically. The fans allow to work longer with hot joints but enventually the temperature will keep rising if the joints keep being sollicitated. The default value is 45°C on Reachy. shutdown temperature: when this temperature is reached, the motor will normally shutdown and stop working until it has cooled down. This is a precaution measure to protect the motor. The default value is 55°C on Reachy. Even though there exists a shutdown temperature, we recommand that when you intend on using the robot for a long period, you let the arms rest and their motors cool down regularly (5 minutes rest every 30 minutes of effort).
`}),e.add({id:81,href:"/sdk/first-moves/record/",title:"Record and play trajectories",description:"Record and play trajectories on Reachy.",content:`You can easily record joint trajectories directly on Reachy, store and replay them later. This page will show you how to implement such mechanisms.
All examples given below will show trajectories record on each of the robot joints. The position of each motor will be stored at a predefined frequency (typically 100Hz). Similarly, the replay will set new target position using the same frequency. Those basics examples does not perform any kind of filtering or modification of the data.
In the following examples, we will assume that you are already connected to your robot and know how to control individual motors.
Recording a trajectory #To record a trajectory, we will simply get the current position of individual motors at a predefiend frequency. We will first define a list of motors that we want to record. In this example, we will only record the joints from the right arm, but you can similarly record a single motor, or all motors of the robot at once.
# assuming we run something like this before:# reachy = ReachySDK(host='192.168.0.42') recorded_joints = [reachy.r_arm.r_shoulder_pitch,reachy.r_arm.r_shoulder_roll,reachy.r_arm.r_arm_yaw,reachy.r_arm.r_elbow_pitch,reachy.r_arm.r_forearm_yaw,reachy.r_arm.r_wrist_pitch,reachy.r_arm.r_wrist_roll,]Now let\u0026rsquo;s define our frequency and record duration:
sampling_frequency = 100 # in Hzrecord_duration = 5 # in sec.Our record loop can then be defined as such:
import timetrajectories = []start = time.time()while (time.time() - start) \u0026lt; record_duration:# We here get the present position for all of recorded jointscurrent_point = [joint.present_position for joint in recorded_joints]# Add this point to the already recorded trajectoriestrajectories.append(current_point)time.sleep(1 / sampling_frequency)If you want to record a demonstration on the robot, first make sure the robot is compliant. Then, put it in the starting position. Run the code, and start moving the robot. After 5 seconds, the loop will stop and the movements you have made on Reachy will be recorded.
Depending on your uses, you can define another duration. You can also choose not to use a specify duration but maybe use start and stop event to record. In such case, the easy way is probably to run the loop within a thread or an asynchronous fonction, so it can run in background.
Visualise your recordings #The trajectories you recorded can be converted to numpy array for more complex processings:
import numpy as nptraj_array = np.array(trajectories)If you are familiar with matplotlib, you can also plot it via:
from matplotlib import pyplot as pltplt.figure()plt.plot(trajectories)Replay a recorded trajectory #Replaying the recorded trajectory basically uses the same loop but set the goal position instead of reading the present position.
But before actually replaying the trajectory, there are a few key points that you should take care of:
First, make sure the joints you are going to move are stiff. Then, if the arm is not in the same position than the one you use as a start position of your recording, the beginning of the replay will be really brutal. It will try to go to the starting position as fast as possible. To avoid that, you can use the goto function to first go to the first point of your trajectories:
from reachy_sdk.trajectory import goto# Set all used joint stifffor joint in recorded_joints:joint.compliant = False# Create a dict associating a joint to its first recorded positionfirst_point = dict(zip(recorded_joints, trajectories[0]))# Goes to the start of the trajectory in 3sgoto(first_point, duration=3.0)Now that we are in position, we can actually play the trajectory. To do that, we simply loop over our recordings and set the goal position of each joints at the same frequency:
import timefor joints_positions in trajectories:for joint, pos in zip(recorded_joints, joints_positions):joint.goal_position = postime.sleep(1 / sampling_frequency)`}),e.add({id:82,href:"/sdk/first-moves/kinematics/",title:"Arms kinematics",description:"Presentation of Reachy's forward and inverse kinematics.",content:`Make sure you checked the safety page before controling the arm.
This page assumes that you went through the Hello World so that you know how to connect to the robot and that you also know how to use the goto() function presented in Controling the arm.
Arm coordinate system #Joint coordinates #If you remember the goto() function, to generate a trajectory for the requested joints you need to pass a dictionnary of joints with the requested position as the goal_positions argument.
For example, to place the right arm in a right angled position, we defined the right_angled_position dictionnary.
right_angled_position = {reachy.r_arm.r_shoulder_pitch: 0,reachy.r_arm.r_shoulder_roll: 0,reachy.r_arm.r_arm_yaw: 0,reachy.r_arm.r_elbow_pitch: -90,reachy.r_arm.r_forearm_yaw: 0,reachy.r_arm.r_wrist_pitch: 0,reachy.r_arm.r_wrist_roll: 0,}and then used goto() like this:
goto(goal_positions=right_angled_position,duration=1.0,interpolation_mode=InterpolationMode.MINIMUM_JERK)Here we have used what is called joint coordinates to move Reachy. This means that we have controlled each joint separately.
The thing is that controlling a robot in joint coordinates can be hard and is often far from what we actually do as humans. When we want to grasp an object in front of us, we think of where we should put our hand, not how to flex each individual muscle to reach this position. This approach relies on the cartesian coordinates: the 3D position and orientation in space, this is where the kinematic model comes into play.
Kinematic model #The kinematic model describes the motion of a robot in mathematical form without considering the forces and torque affecting it. It only focuses on the geometric relationship between elements.
We have defined the whole kinematic model of the arm. This means the translation and rotation required to go from one joint to the next one. On a right arm equipped with a force gripper this actually look like this:
Motor Translation Rotation r_shoulder_pitch (0, -0.019, 0) (0, 1, 0) r_shoulder_roll (0, 0, 0) (1, 0, 0) r_arm_yaw (0, 0, 0) (0, 0, 1) r_elbow_pitch (0, 0, -0.28) (0, 1, 0) r_forearm_yaw (0, 0, 0) (0, 0, 1) r_wrist_pitch (0, 0, -0.25) (0, 1, 0) r_wrist_roll (0, 0, -0.0325) (1, 0, 0) r_gripper (0, -0.01, -0.075) (0, 0, 0) To use and understand the kinematic model, you need to know how Reachy coordinate system is defined (from Reachy\u0026rsquo;s perspective), see below:
the X axis corresponds to the foward arrow, the Y axis corresponds to the right to left arrow, the Z axis corresponds to the up arrow. The origin of this coordinate system is located in the upper part of the robot trunk, inside Reachy. Basically, if you imagine a segment going from the left shoulder to the right shoulder of the robot, the origin is the middle of this segment, which corresponds to behind the center of Pollen\u0026rsquo;s logo on Reachy\u0026rsquo;s torso.
The units used for this coordinate system are the meter. So the point (0.3, -0.2, 0) is 30cm in front of the origin, 20cm to the right and at the same height.
Switching between joint and cartesian coordinates #Forward and inverse kinematics are a way to go from one coordinates system to the other:
forward kinematics: joint coordinates –\u0026gt; cartesian coordinates, inverse kinematics: cartesian coordinates –\u0026gt; joint coordinates. Forward kinematics #Using the kinematic model defined above, we can compute the 3D position and orientation of the right or left end-effector with the forward_kinematics method.
We consider the end-effector to be in a virtual joint located in the gripper and referred as \u0026lsquo;right_tip\u0026rsquo; or \u0026rsquo;left_tip\u0026rsquo; in the urdf file, as shown below.
The red dot corresponds to the \u0026lsquo;right_tip\u0026rsquo;.
You can see the right and left end-effectors animated below.
Your browser does not support the video element.
Each arm has a forward_kinematics method. To use it, you first need to connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.r_arm.forward_kinematics()\u0026gt;\u0026gt;\u0026gt; array([[ 0.04622308, -0.03799621, -0.99820825, 0.31144822],[ 0.10976691, 0.99341829, -0.03273101, -0.19427524],[ 0.99288199, -0.1080573 , 0.05008958, -0.4255104 ],[ 0. , 0. , 0. , 1. ]])The 4x4 matrix returned by the forward_kinematics method is what is often called a pose. It actually encodes both the 3D translation (as a 3D vector) and the 3D rotation (as a 3x3 matrix) into one single representation.
\$\$\\begin{bmatrix} R_{11} \u0026amp; R_{12} \u0026amp; R_{13} \u0026amp; T_x\\\\\\ R_{21} \u0026amp; R_{22} \u0026amp; R_{23} \u0026amp; T_y\\\\\\ R_{31} \u0026amp; R_{32} \u0026amp; R_{33} \u0026amp; T_z\\\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix}\$\$
The instruction
reachy.r_arm.forward_kinematics()returns the current pose of the right end-effector, based on the present position of every joint in the right arm.
You can also compute the pose for a given joints position, to do that just pass the list of position as argument of forward_kinematics. Be careful to respect the order of the position you give and to give all the joints in the arm kinematic chain (i.e. from shoulder_pitch to wrist_roll).
For example, we can compute the forward kinematics for the right-angle position we defined earlier.
reachy.r_arm.forward_kinematics(right_angle_position.values())\u0026gt;\u0026gt;\u0026gt; array([[ 0. , 0. , -1. , 0.3675],[ 0. , 1. , 0. , -0.202 ],[ 1. , 0. , 0. , -0.28 ],[ 0. , 0. , 0. , 1. ]])With this result, we can tell that when the right arm is in the right angle position, the right end-effector is 37cm in front of the origin, 20cm to the left and 28cm below the origin.
As of the rotation matrix, the identity matrix corresponds to the zero position of the robot which is when the hand is facing toward the bottom.
Here we obtained the rotation matrix
\$\$\\begin{bmatrix} 0 \u0026amp; 0 \u0026amp; -1\\\\\\ 0 \u0026amp; 1 \u0026amp; 0 \\\\\\ 1 \u0026amp; 0 \u0026amp; 0 \\end{bmatrix}\$\$
We can use scipy to understand what this matrix represents.
from scipy.spatial.transform import Rotation as Rimport numpy as npR.from_matrix([[0, 0, -1],[0, 1, 0],[1, 0, 0],]).as_euler('xyz', degrees=True)\u0026gt;\u0026gt;\u0026gt; array([ 0. , -89.99999879, 0. ])So scipy tells us that a rotation of -90° along the y axis has been made to get this matrix, which is coherent with the result because having the hand facing forward corresponds to this rotation according to Reachy\u0026rsquo;s xyz axis that we saw above.
Inverse kinematics #Knowing where you arm is located in the 3D space can be useful but most of the time what you want is to move the arm in cartesian coordinates. You want to have the possibility to say: “move your hand to [x, y, z] with a 90° rotation around the Y axis”.
This is what inverse kinematics does. We have provided a method to help you with that. You need to give it a 4x4 target pose, like the one given by the forward kinematics, and an initial joint state.
Example: square movement #Defining the poses #To make this more concrete, let\u0026rsquo;s first try with a simple example. We will make the right hand draw a square in 3D space. To draw it, we will define the four corners of a square and Reachy\u0026rsquo;s right hand will go to each of them.
The virtual corner is represented below.
For our starting corner A, let\u0026rsquo;s imagine a point in front of the robot, on its right and below its base. With Reachy coordinate system, we can define such a point with the following coordinates:
\$\$A = \\begin{pmatrix}0.3 \u0026amp; -0.4 \u0026amp; -0.3\\end{pmatrix}\$\$
The coordinates of B should match A except the z component wich should be higher. Hence
\$\$B = \\begin{pmatrix}0.3 \u0026amp; -0.4 \u0026amp; 0.0\\end{pmatrix}\$\$
For the corner C, we want a point on the same z level as B in the inner space of Reachy and in the same plane as A and B so we only need to change the y component of B. We can take for example
\$\$C = \\begin{pmatrix}0.3 \u0026amp; -0.1 \u0026amp; 0.0\\end{pmatrix}\$\$
And to complete our corners we can deduce D from A and C. D coordinates should match C except its z component which must the same as A. Hence
\$\$D = \\begin{pmatrix}0.3 \u0026amp; -0.1 \u0026amp; -0.3\\end{pmatrix}\$\$
Remember that you always have to provide poses to the inverse kinematics that are actually reachable by the robot. If you\u0026rsquo;re not sure whether the 3D point that you defined is reachable by Reachy, you can move the arm with your hand in compliant mode, ask the forward kinematics and check the 3D translation component of the returned pose.
But having the 3D position is not enough to design a pose. You also need to provide the 3D orientation via a rotation matrix. The rotation matrix is often the tricky part when building a target pose matrix.
Keep in mind that the identity rotation matrix corresponds to the zero position of the robot which is when the hand is facing toward the bottom. So if we want the hand facing forward when drawing our virtual square, we need to rotate it from -90° around the y axis, as we saw in the forward kinematics part.
We know from before which rotation matrix corresponds to this rotation, but we can use scipy again to generate the rotation matrix for given rotations.
print(np.around(R.from_euler('y', np.deg2rad(-90)).as_matrix(), 3))\u0026gt;\u0026gt;\u0026gt; [[ 0. -0. -1.][ 0. 1. -0.][ 1. 0. 0.]]We got the rotation matrix that we expected!
As mentionned, building the pose matrix can be hard, so don\u0026rsquo;t hesitate to use scipy to build your rotation matrix. You can also move the arm with your hand where you want it to be and use the forward kinematics to get an approximation of the target pose matrix you would give to the inverse kinematics.
Here, having the rotation matrix and the 3D positions for our points A and B, we can build both target pose matrices.
A = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.4], [1, 0, 0, -0.3],[0, 0, 0, 1], ])B = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.4], [1, 0, 0, 0.0],[0, 0, 0, 1], ])C = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.1], [1, 0, 0, 0.0],[0, 0, 0, 1], ])D = np.array([[0, 0, -1, 0.3],[0, 1, 0, -0.1], [1, 0, 0, -0.3],[0, 0, 0, 1], ])Computing the joint positions #inverse_kinematics() takes one optional argument, q0, which is the starting point of the inverse kinematics computation. If no q0 is given, q0 is considered to be equal to the present joints position.
Inverse kinematics is a really powerful way to define motions in coordinate systems that fits better with the defintion of many tasks (grasp the bottle in (x, y, z) for instance). Yet, this approach has also some important limitations.
It\u0026rsquo;s important to understand that while the forward kinematics has a unique and well defined solution, the inverse kinematics is a much harder and ill defined problem. A Right Arm with a Gripper has 8 Degrees Of Freedom meaning that you may have multiple solutions to reach the same 3D point in space.
Because the inverse kinematics algorithm used is based on optimisation techniques, giving a starting point q0 may have a tremendous influence on the final result.
Now let\u0026rsquo;s use the inverse kinematics to move between our two points A and B! We will consider that the starting point is the right angled position that we used before, then the arm will go to A and finish at B.
joint_pos_A = reachy.r_arm.inverse_kinematics(A)joint_pos_B = reachy.r_arm.inverse_kinematics(B)joint_pos_C = reachy.r_arm.inverse_kinematics(C)joint_pos_D = reachy.r_arm.inverse_kinematics(D)Sending the movements commands #As before, we use the goto() to send moving instructions to the arm.
import time# put the joints in stiff modereachy.turn_on('r_arm')# use the goto functiongoto({joint: pos for joint,pos in zip(reachy.r_arm.joints.values(), joint_pos_A)}, duration=1.0)time.sleep(0.5)goto({joint: pos for joint,pos in zip(reachy.r_arm.joints.values(), joint_pos_B)}, duration=1.0)time.sleep(0.5)goto({joint: pos for joint,pos in zip(reachy.r_arm.joints.values(), joint_pos_C)}, duration=1.0)time.sleep(0.5)goto({joint: pos for joint,pos in zip(reachy.r_arm.joints.values(), joint_pos_D)}, duration=1.0)# put the joints back to compliant mode# use turn_off_smoothly to prevent the arm from falling hardreachy.turn_off_smoothly('r_arm')The result should look like this:
Your browser does not support the video element.
`}),e.add({id:83,href:"/sdk/first-moves/intro/",title:"Once you're connected",description:"Quick overview of what is information is available for the user once connected to the robot.",content:`If you followed the instructions from [\u0026ldquo;Finding Reachy\u0026rsquo;s IP\u0026rdquo;], you know how to get Reachy\u0026rsquo;s IP address and how to connect to the robot with the command:
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPThe reachy object #The reachy object instanciated above is the main tool to access the information coming from Reachy\u0026rsquo;s sensors (joints, force sensors, cameras) and to control each part of the robot (left/right arm, head).
reachy\u0026rsquo;s attributes #The reachy object has 8 attributes and 2 methods that we will quickly present here, more detailed information are given in the dedicated pages after this one.
reachy.fans #DeviceHolder object. We made the DeviceHolder class to have an object that can contain all sensors of the same type (eg. Fan, ForceSensor, Joint). The goal was to not overcrowd the ReachySDK class with all devices.
Here, reachy.fans contains all the fans in Reachy. Each fan can then be accessed individually or you can get and set all the fan states at once.
reachy.fans\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;Fan name=\u0026quot;l_shoulder_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_elbow_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_wrist_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_shoulder_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_elbow_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_wrist_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_antenna_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_antenna_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026gt;reachy.force_sensors #DeviceHolder object containing all the force sensors in Reachy. In the 2021 Reachy version there are only two force sensors, one in the gripper of each arm. As with the fans, each force sensor can be accessed individually or all at once.
reachy.force_sensors\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;ForceSensor name=\u0026quot;l_force_gripper\u0026quot; force=\u0026quot;31.30\u0026quot;\u0026gt;\u0026lt;ForceSensor name=\u0026quot;r_force_gripper\u0026quot; force=\u0026quot;-67.02\u0026quot;\u0026gt;\u0026gt;reachy.head #Head object. Contains the three joints composing the Orbita actuator along with methods for its kinematics or to control it.
reachy.head\u0026gt;\u0026gt;\u0026gt; \u0026lt;Head joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;neck_roll\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_pitch\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_yaw\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_antenna\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_antenna\u0026quot; pos=\u0026quot;0.00\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;reachy.joints #Joint object containing every joint of the robot, from its arms to its head and antennas. This is useful when you want to get information, like the position, from all joints at once.
reachy.joints\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;Joint name=\u0026quot;l_shoulder_pitch\u0026quot; pos=\u0026quot;-0.86\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_shoulder_roll\u0026quot; pos=\u0026quot;-0.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_arm_yaw\u0026quot; pos=\u0026quot;-81.45\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_elbow_pitch\u0026quot; pos=\u0026quot;-51.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_forearm_yaw\u0026quot; pos=\u0026quot;-16.28\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_pitch\u0026quot; pos=\u0026quot;-41.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_roll\u0026quot; pos=\u0026quot;-21.26\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_gripper\u0026quot; pos=\u0026quot;-3.08\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;29.65\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_roll\u0026quot; pos=\u0026quot;-0.94\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_arm_yaw\u0026quot; pos=\u0026quot;-7.60\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_elbow_pitch\u0026quot; pos=\u0026quot;-71.78\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_forearm_yaw\u0026quot; pos=\u0026quot;-0.73\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_pitch\u0026quot; pos=\u0026quot;-43.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_roll\u0026quot; pos=\u0026quot;-37.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_gripper\u0026quot; pos=\u0026quot;19.50\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_antenna\u0026quot; pos=\u0026quot;140.32\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_antenna\u0026quot; pos=\u0026quot;79.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_roll\u0026quot; pos=\u0026quot;-21.58\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_pitch\u0026quot; pos=\u0026quot;-79.71\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_yaw\u0026quot; pos=\u0026quot;-59.27\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;reachy.l_arm #Arm object containing every joint in the left arm along with its kinematics methods.
reachy.l_arm\u0026gt;\u0026gt;\u0026gt; \u0026lt;Arm side=\u0026quot;left\u0026quot; joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;l_shoulder_pitch\u0026quot; pos=\u0026quot;-0.86\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_shoulder_roll\u0026quot; pos=\u0026quot;-0.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_arm_yaw\u0026quot; pos=\u0026quot;-81.45\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_elbow_pitch\u0026quot; pos=\u0026quot;-51.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_forearm_yaw\u0026quot; pos=\u0026quot;-16.28\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_pitch\u0026quot; pos=\u0026quot;-41.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_wrist_roll\u0026quot; pos=\u0026quot;-21.26\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;l_gripper\u0026quot; pos=\u0026quot;-3.08\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;reachy.left_camera #Camera object. It is used to recover the last image captured by the left camera and also to control the motorized zoom attached to the camera.
reachy.left_camera\u0026gt;\u0026gt;\u0026gt; \u0026lt;Camera side=\u0026quot;left\u0026quot; resolution=(720, 1280, 3)\u0026gt;reachy.r_arm #Arm object containing every joint in the right arm along with its kinematics methods.
reachy.r_arm\u0026gt;\u0026gt;\u0026gt; \u0026lt;Arm side=\u0026quot;right\u0026quot; joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;29.65\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_roll\u0026quot; pos=\u0026quot;-0.94\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_arm_yaw\u0026quot; pos=\u0026quot;-7.60\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_elbow_pitch\u0026quot; pos=\u0026quot;-71.78\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_forearm_yaw\u0026quot; pos=\u0026quot;-0.73\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_pitch\u0026quot; pos=\u0026quot;-43.03\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_roll\u0026quot; pos=\u0026quot;-37.10\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_gripper\u0026quot; pos=\u0026quot;19.50\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;reachy.right_camera #Camera object. It is used to recover the last image captured by the right camera and also to control the motorized zoom attached to the camera.
reachy.right_camera\u0026gt;\u0026gt;\u0026gt; \u0026lt;Camera side=\u0026quot;right\u0026quot; resolution=(720, 1280, 3)\u0026gt;reachy.turn_on() #Method to turn on the specified Reachy\u0026rsquo;s parts (either left/right arm, head or even all at once). Turning on a part means putting all the joints in this part in stiff mode. See next section for more information on what the stiff mode is for a motor.
reachy.turn_on('reachy')Using \u0026lsquo;reachy\u0026rsquo; as argument turns on all the parts in Reachy.
reachy.turn_off() #Method to turn off the specified Reachy\u0026rsquo;s parts (either left/right arm, head or even all at once). Turning off a part means putting all the joints in this part in compliant mode. See next section for more information on what the compliant mode is for a motor.
reachy.turn_off('reachy')`}),e.add({id:84,href:"/sdk/first-moves/head/",title:"Controlling the head",description:"Control the head",content:`Make sure you checked the safety page before controling the arm.
This section assumes that you went through the Hello World so that you know how to connect to the robot.
Head presentation #Reachy\u0026rsquo;s head is composed of three parts:
a front side where two cameras equipped with motorized zoom are attached, a back side equiped with two antennas to convey emotions along with two fans in the inner part to cool down the components inside the head, a neck ball joint, thanks to our Orbita actuator. Your browser does not support the video element.
The complete head\u0026rsquo;s specifications are given here.
Front and back #Below you can see Reachy\u0026rsquo;s head front and back supported by the Orbita actuator.
Reachy\u0026rsquo;s neck: Orbita actuator #The Orbita actuator is a unique technology developed by Pollen Robotics’ R\u0026amp;D team. This ball joint actuator allows unpreceded dynamic and multi-directional movement. This joint is used as the neck of Reachy and permits to mimic the degrees of freedom of the human neck. With this, the experience of controling Reachy with Virtual Reality gets even more immersive.
Orbita can be controlled as a 3D rotation.
We wrote a Medium article on Orbita to explain how it works and what inspired us to create it. If you have 10 minutes, go check it out!
Controling each part #Before starting to control it, connect to your Reachy. As in the other pages:
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.head\u0026gt;\u0026gt;\u0026gt; \u0026lt;Head joints=\u0026lt;Holder\u0026lt;Joint name=\u0026quot;l_antenna\u0026quot; pos=\u0026quot;121.26\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_antenna\u0026quot; pos=\u0026quot;-10.70\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_roll\u0026quot; pos=\u0026quot;9.16\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_pitch\u0026quot; pos=\u0026quot;-6.09\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_yaw\u0026quot; pos=\u0026quot;-14.92\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;\u0026gt;The reachy.head object has five joints: one for each Orbita\u0026rsquo;s disks (three in total) and one per antenna. All the joints in Reachy\u0026rsquo;s head are in the reachy.head.joints object and each joint being an attribute of reachy.head, they can also be accessed individually.
reachy.head.joints\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;Joint name=\u0026quot;l_antenna\u0026quot; pos=\u0026quot;-2.49\u0026quot; mode=\u0026quot;stiff\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_antenna\u0026quot; pos=\u0026quot;-0.44\u0026quot; mode=\u0026quot;stiff\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_roll\u0026quot; pos=\u0026quot;-5.72\u0026quot; mode=\u0026quot;stiff\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_pitch\u0026quot; pos=\u0026quot;-19.77\u0026quot; mode=\u0026quot;stiff\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;neck_yaw\u0026quot; pos=\u0026quot;-54.11\u0026quot; mode=\u0026quot;stiff\u0026quot;\u0026gt;\u0026gt;Orbita: look_at method #Each motor in Orbita can be controlled individually, but having the head doing the movements you desire using this will be very hard as it involves mathematical transformation with the use of quaternions.
To make things simpler, we implemented the look_at method which hides all the maths.
With this, instead of piloting each disk individually you can specify a point in the space at which the head will look.
The coordinates of the specified point are expressed in Reachy\u0026rsquo;s coordinates system, as presented in the Kinematics page.
Fox example, if you want Reachy to look forward you can send it the following.
reachy.turn_on('head') # Don't forget to put the hand in stiff modereachy.head.look_at(x=0.5, y=0, z=0, duration=1.0)Remember that the coordinates in Reachy\u0026rsquo;s coordinates system are in meters.
You can use multiple look_at to chain head movements.
Your browser does not support the video element.
Here is the code to reproduce this.
import timelook_right = reachy.head.look_at(x=0.5, y=-0.5, z=0.1, duration=1.0)time.sleep(0.1)look_down = reachy.head.look_at(x=0.5, y=0, z=-0.4, duration=1.0)time.sleep(0.1)look_left = reachy.head.look_at(x=0.5, y=0.3, z=-0.3, duration=1.0)time.sleep(0.1)look_front = reachy.head.look_at(x=0.5, y=0, z=0, duration=1.0)The best way to understand how to use the look_at is to play with it. Picture a position you would like Reachy\u0026rsquo;s head to be in, guess a point which could match for the look_at and check if you got it right!
And don\u0026rsquo;t forget to put the head back to compliant mode to protect the motors, once you\u0026rsquo;re done using them.
reachy.turn_off('head')Another cool thing is that we can combine Reachy\u0026rsquo;s kinematics with the look_at so that Reachy\u0026rsquo;s head follows its hand!
Your browser does not support the video element.
reachy.turn_on('head')x, y, z = reachy.r_arm.forward_kinematics()[:3, -1]reachy.head.look_at(x=x, y=y, z=z, duration=1.0)time.sleep(0.5)while True:x, y, z = reachy.r_arm.forward_kinematics()[:3, -1]reachy.head.look_at(x=x, y=y, z=z, duration=0.1)What the code says is that we compute the forward kinematics of Reachy\u0026rsquo;s right arm, and the x, y, z of Reachy\u0026rsquo;s right end-effector in the Reachy\u0026rsquo;s coordinates system will be the coordinates of the point used by the look_at.
Cameras #The dedicated page on Reachy\u0026rsquo;s cameras can be found here.
Antennas #The antennas can be controlled like any other joint in Reachy. You can turn the motors stiff/compliant, get the present position, the temperature, set a goal position, \u0026hellip; For more details on the attributes of a Reachy\u0026rsquo;s joint, go to the joints section of \u0026lsquo;Controling the arm\u0026rsquo; page.
The antennas are a powerful tool to convey emotions to Reachy. For example just by moving the antennas, you can tell whether Reachy is happy or not.
def happy_antennas():reachy.head.l_antenna.speed_limit = 0.0reachy.head.r_antenna.speed_limit = 0.0for _ in range(9):reachy.head.l_antenna.goal_position = 10.0reachy.head.r_antenna.goal_position = -10.0time.sleep(0.1)reachy.head.l_antenna.goal_position = -10.0reachy.head.r_antenna.goal_position = 10.0time.sleep(0.1)reachy.head.l_antenna.goal_position = 0.0reachy.head.r_antenna.goal_position = 0.0def sad_antennas():reachy.head.l_antenna.speed_limit = 70.0reachy.head.r_antenna.speed_limit = 70.0reachy.head.l_antenna.goal_position = 140.0reachy.head.r_antenna.goal_position = -140.0time.sleep(5.0)reachy.head.l_antenna.goal_position = 0.0reachy.head.r_antenna.goal_position = 0.0happy_antennas()sad_antennas()The result should look like the following.
Your browser does not support the video element.
Combining this with head movements amplifies the emotions transmitted. Having Reachy lowering its head makes it even sadder\u0026hellip;
reachy.head.look_at(0.5, 0, -0.4, 1.0)sad_antennas()reachy.head.look_at(0.5, 0, -0.0, 1.0)Your browser does not support the video element.
Use your imagination to combine antennas and head movements and create new emotions for Reachy!
Fans #The two fans inside Reachy\u0026rsquo;s head can also be controlled as any other fan in Reachy. The dedicated page on fan controling can be found here.
`}),e.add({id:85,href:"/sdk/first-moves/fans/",title:"Controlling the fans",description:"How to control the fans inside Reachy's arms and head.",content:`This section assumes that you went through the Hello World so that you know how to connect to the robot.
Reachy is equipped with fans to cooldown the joints when they are working. Each arm has three fans and two fans are in the head.
First, connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.fans\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;Fan name=\u0026quot;l_shoulder_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_elbow_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_wrist_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_shoulder_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_elbow_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_wrist_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_antenna_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_antenna_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026gt;As explained in the safety page, the temperature of each joint is controlled internally in Reachy and if it reaches a certain value, the corresponding fan turns on. However, you might want to turn them on sooner so that the joints work longer on a demanding task.
The reachy.fans object contains each fan. You can have access to each fan individually or to all at once.
for fan in reachy.fans.values():print(fan)\u0026gt;\u0026gt;\u0026gt; \u0026lt;Fan name=\u0026quot;l_shoulder_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_elbow_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_wrist_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_shoulder_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_elbow_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_wrist_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;l_antenna_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;\u0026lt;Fan name=\u0026quot;r_antenna_fan\u0026quot; state=\u0026quot;off\u0026quot;\u0026gt;Each Fan object has two attributes:
name string with the fan\u0026rsquo;s name, is_on boolean, False when the fan is off and True when it is on. and two methods: on() which turns the fan on, off() which turns the fan off. Thus you can easily turn on a fan.
reachy.fans.r_wrist_fan.on()reachy.fans.r_wrist_fan.is_on\u0026gt;\u0026gt;\u0026gt; Truereachy.fans.r_wrist_fan.off()`}),e.add({id:86,href:"/sdk/first-moves/cameras/",title:"Reachy's cameras",description:"How to get the images from Reachy's cameras and pilot the motorized zooms.",content:`This section assumes that you went through the Hello World so that you know how to connect to the robot.
Reachy 2023 has two high quality cameras which can deliver up to 1080p at 30 fps. Each camera is equipped with a motorized zoom allowing to adapt the zoom and focus levels to the situation you\u0026rsquo;re working on.
Each camera can be accessed separately with reachy.left_camera and reachy.right_camera.
First, connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.left_camera\u0026gt;\u0026gt;\u0026gt; \u0026lt;Camera side=\u0026quot;left\u0026quot; resolution=(720, 1280, 3)\u0026gt;The left and right sides are considered from Reachy point of view.
Get the images #The last image captured by each camera can be obtained with the .last_frame attribute.
import cv2 as cvimg = reachy.right_camera.last_framecv.imshow('right_frame', img)cv.waitKey(0)cv.destroyAllWindows()Video stream #If you are directly working on Reachy #You can visualize the video feed from both cameras easily with a python script made for that.
If reachy_sdk_server, the ROS2 server for Reachy SDK, is running.
In a terminal:
\$ python3 ~/reachy_ws/src/reachy_2023/camera_controllers/examples/view_cam.py \u0026quot;camera_you_want\u0026quot; rosFor example, if you want to visualize the left camera:
\$ python3 ~/reachy_ws/src/reachy_2023/camera_controllers/examples/view_cam.py left rosIf reachy_sdk_server is not running, you can work with opencv.
\$ python3 ~/reachy_ws/src/reachy_2023/camera_controllers/examples/view_cam.py left opencvNOTE: This will only work if you are working directly on the robot with a computer screen plugged to it and not remotely.
If you are working remotely #You can also visualize the video feed from any computer, considering it is on the same network as Reachy and that you know Reachy\u0026rsquo;s IP address.
To view the left camera:
cd ~/reachy-sdk/reachy_sdk/examplespython3 view_cam_sdk.py left --ip_address '192.168.0.42' # Replace with the actual IPControl the motorized zoom #The piloting of Reachy\u0026rsquo;s zooms is using zoom_kurokesu, a custom python library.
Zoom level #There are three zoom levels available: \u0026lsquo;in\u0026rsquo;, \u0026lsquo;out\u0026rsquo;, \u0026lsquo;inter\u0026rsquo;.
\u0026lsquo;in\u0026rsquo;: for close objects, \u0026lsquo;out\u0026rsquo;: for further objects, \u0026lsquo;inter\u0026rsquo;: in between the \u0026lsquo;in\u0026rsquo; and \u0026lsquo;out\u0026rsquo; positions. The zoom levels have been selected so that if you set the same zoom level on both cameras, you should see the same image (slightly shifted of course considering the cameras are few centimeters from each other).
The current zoom level applied to a camera can be checked.
reachy.left_camera.zoom_level\u0026gt;\u0026gt;\u0026gt; \u0026lt;ZoomLevel.INTER: 2\u0026gt;reachy.right_camera.zoom_level\u0026gt;\u0026gt;\u0026gt; \u0026lt;ZoomLevel.INTER: 2\u0026gt;The zoom level can be set with ZoomLevel from reachy_sdk.camera.
from reachy_sdk.camera import ZoomLevelreachy.left_camera.zoom_level = ZoomLevel.OUTreachy.right_camera.zoom_level = ZoomLevel.INYou should hear the Reachy\u0026rsquo;s zooms motors moving.
Each zoom level sends positions instructions relatively to a base position and it may happen that the base positions get a bit drifted. The homing instruction bring the zoom motors to their limit and reset the base positions from it.
reachy.right_camera.zoom_homing()Once the homing executed, you can reset a zoom position.
reachy.left_camera.zoom_level = ZoomLevel.INTERAutofocus #Changing the zoom level does not adapt the focus directly. However, autofocus is available! To use it:
reachy.left_camera.start_autofocus()NOTE: the autofocus algorithm will not focus on one specific area of the image, it will try to give the clearest image overall.
Zoom speed #The speed of the zoom motors can also be changed along with the level.
The value of the speed is an int between 4000 and 40000, by default the value is at 10000 but you can change it easily.
reachy.left_camera.zoom_speed\u0026gt;\u0026gt;\u0026gt; 10000reachy.left_camera.zoom_speed = 30000reachy.left_camera.zoom_speed\u0026gt;\u0026gt;\u0026gt; 30000`}),e.add({id:87,href:"/sdk/first-moves/arm/",title:"Controlling the arm",description:"What are the joints in Reachy's arms, what information are available and how to control them.",content:`Make sure you checked the safety page before controlling the arm.
This section assumes that you went through the Hello World so that you know how to connect to the robot.
Arm presentation #Reachy\u0026rsquo;s arm offers 7 degrees of freedom + 1 provided by the gripper and is composed of 8 joints.
The arm\u0026rsquo;s mechanical specifications are given here but as a reminder, the arm schematic is given below:
The joints #Each joint has a unique name and uid. To access a specific joint, you can either use reachy.joints which has each joint in the robot as attribute or reachy.l_arm/reachy.r_arm depending on which arm the joint belongs to of course.
First, connect to your Reachy.
from reachy_sdk import ReachySDKreachy = ReachySDK(host='192.168.0.42') # Replace with the actual IPreachy.joints.r_shoulder_pitch\u0026gt;\u0026gt;\u0026gt; \u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;27.98\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;The name and the id are attributes of the returned Joint object.
reachy.r_arm.r_shoulder_pitch.name\u0026gt;\u0026gt;\u0026gt; 'r_shoulder_pitch'reachy.r_arm.r_shoulder_pitch.uid\u0026gt;\u0026gt;\u0026gt; 8The uid returned by the sdk is different from the id you may have seen in the mechanical specifications. The motor\u0026rsquo;s id in the mechanical specification is the one used at lower level by the dxl bus to communicate with the motors whereas the uid that you see in the sdk is the one used by the different grpc services.
What information do you have access to? #From the joints #As explained, each joint composing an arm can be accessed using reachy.r_arm for the right arm and reachy.l_arm for the left arm.
All the joints of a given arm can also be accessed simultaneously with the .joints attribute.
reachy.r_arm.joints\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;Joint name=\u0026quot;r_shoulder_pitch\u0026quot; pos=\u0026quot;27.98\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_shoulder_roll\u0026quot; pos=\u0026quot;-5.51\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_arm_yaw\u0026quot; pos=\u0026quot;-6.73\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_elbow_pitch\u0026quot; pos=\u0026quot;-71.34\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_forearm_yaw\u0026quot; pos=\u0026quot;0.15\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_pitch\u0026quot; pos=\u0026quot;-41.63\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_wrist_roll\u0026quot; pos=\u0026quot;-20.38\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026lt;Joint name=\u0026quot;r_gripper\u0026quot; pos=\u0026quot;19.50\u0026quot; mode=\u0026quot;compliant\u0026quot;\u0026gt;\u0026gt;This can be useful when you want to recover information like the position or the temperature of multiple arm joints at once.
Beside the joint name and uid there are multiple information which can be obtained from each joint, these are summarized in the registers() method.
reachy.r_arm.r_shoulder_pitch.registers()\u0026gt;\u0026gt;\u0026gt; {'name': 'r_shoulder_pitch','uid': 8,'present_position': 22.441230263406165,'temperature': 41.0,'compliant': True,'goal_position': -0.32800019809599856,'speed_limit': 0.0,'torque_limit': 100.0,'pid': (32.0, 0.0, 0.0)}present_position #You can get the present position of each joint with this attribute.
reachy.r_arm.r_shoulder_pitch.present_position\u0026gt;\u0026gt;\u0026gt; 22.4This can be useful in situations such as when you want to record a movement. For example you want to lift an object, you move the arm once yourself, store the present_position of each joint involved and replay it. This is what we used to get the movements in our Tictactoe application!
Also if you want to teach movements to the robot with learning technics, storing the present_position of the joints will help you build a dataset.
temperature #You also have access to each motor temperature with the temperature attribute of each joint. This temperature should be checked to make sure that the robot can operate correctly. The temperature is also monitored internally in Reachy and fans are turned on when the joints are heating.
Check the safety page before controlling the arm for more information.
reachy.r_arm.r_shoulder_pitch.temperature\u0026gt;\u0026gt;\u0026gt; 41.0compliant #As explained in the [previous page], each motor in Reachy has two compliance modes: compliant where the motor is soft and can be freely turned by hand and stiff where the motor is hard and can only be moved by setting a target position.
A joint\u0026rsquo;s compliance mode can be easily changed by setting its compliant attribute. At startup by default, all joints are compliant.
reachy.r_arm.r_shoulder_pitch.compliant\u0026gt;\u0026gt;\u0026gt; Truereachy.r_arm.r_shoulder_pitch.compliant = False # stiff modereachy.r_arm.r_shoulder_pitch.compliant\u0026gt;\u0026gt;\u0026gt; Falsereachy.r_arm.r_shoulder_pitch.compliant = True # compliant modereachy.r_arm.r_shoulder_pitch.compliant\u0026gt;\u0026gt;\u0026gt; TrueBecause you will often want to turn stiff/compliant all the joints in an arm, in the head or each Reachy\u0026rsquo;s joints, the methods turn_on() and turn_off() are provided in the SDK.
reachy.turn_on(part: str): turn all the joints in the requested part in stiff mode, reachy.turn_off(part: str): turn all the joints in the requested part in compliant mode. The part argument in these methods can either be \u0026lsquo;reachy\u0026rsquo;, \u0026rsquo;l_arm\u0026rsquo;, \u0026lsquo;r_arm\u0026rsquo; or \u0026lsquo;head\u0026rsquo;. Using \u0026lsquo;reachy\u0026rsquo; will turn on/off each joint in Reachy.
reachy.turn_on('r_arm')Check Reachy\u0026rsquo;s right arm after sending this command, if you try to move it with your hands you should feel the resistance applied by the right arm\u0026rsquo;s motors to stay in their position. You can compare with the left arm\u0026rsquo;s motors which should be in compliant mode.
Once you\u0026rsquo;re done using the arm, don\u0026rsquo;t forget to turn it back to compliant mode.
reachy.turn_off('r_arm')Switching from stiff to compliant for a joint can present a risk of harming Reachy because if the arm was stiff and in the air, it will just fall on what is below him. For example if you have Reachy above a table, place its arm in stiff mode and then in compliant mode, the arm will fall quite hard on the table unless you place your hand below to support the fall.
That is why we also implemented the turn_off_smoothly method. With this, we first reduce the torque limit of the joint and then turn it to compliant mode. This result in a smoother transition between the two states.
See the difference below where both Reachy\u0026rsquo;s arms are up and in stiff mode. To put them in compliant mode, we use turn_off on the left arm and turn_off_smoothly for the right arm.
Your browser does not support the video element.
reachy.turn_on('reachy')reachy.turn_off('l_arm')reachy.turn_off_smoothly('r_arm')goal_position #The goal_position attribute of a joint is what is used to set a new joint\u0026rsquo;s target position to make it move. However, we recommend using the goto() function to move the motors which provides better control on the joint\u0026rsquo;s trajectories.
torque/speed_limit #The torque limit represents the percentage of maximum torque that the motor will use to stay in its present position when it is in stiff mode. We set it to 100% on each joint.
reachy.r_arm.r_shoulder_pitch.torque_limit\u0026gt;\u0026gt;\u0026gt; 100.0According to the motors documentation, the speed is in rpm (raw per minute).
source: https://emanual.robotis.com/docs/en/dxl/ax/ax-18a/#ccw-angle-limit We set the speed limit to 0 on each joint, meaning that the motors work at maximum speed.
reachy.r_arm.r_shoulder_pitch.speed_limit\u0026gt;\u0026gt;\u0026gt; 0.0IMPORTANT We recommend you NOT to change these values. When you want to make movements with Reachy, it\u0026rsquo;s better to replay recorded trajectories or to work with the [goto() function].
pid #You can get and set the pid of each joint with the pid attribute.
reachy.r_arm.r_shoulder_pitch.pid\u0026gt;\u0026gt;\u0026gt; (32.0, 0.0, 0.0)If you are familiar with control theory, you\u0026rsquo;ll know what it represents, if not don\u0026rsquo;t worry just ignore it!
From the force sensor #In the 2023 version of Reachy, only one force sensor is used per arm and it is placed in the gripper to determine if the gripper has an object in it or not.
The force sensor is a 0.78kg micro load cell, it is placed in the arm\u0026rsquo;s gripper as shown below
The force sensor of each arm is accessible with reachy.force_sensors.
reachy.force_sensors\u0026gt;\u0026gt;\u0026gt; \u0026lt;Holder\u0026lt;ForceSensor name=\u0026quot;l_force_gripper\u0026quot; force=\u0026quot;29.76\u0026quot;\u0026gt;\u0026lt;ForceSensor name=\u0026quot;r_force_gripper\u0026quot; force=\u0026quot;-67.72\u0026quot;\u0026gt;\u0026gt;For each force sensor, you can get its name and its force value.
reachy.force_sensors.l_force_gripper.name\u0026gt;\u0026gt;\u0026gt; 'l_force_gripper'reachy.force_sensors.l_force_gripper.force\u0026gt;\u0026gt;\u0026gt; 29.8The force value measures small deformations of the cell happening when an object is in the gripper. The interesting thing with this is that you can know how much Reachy is squeezing an object and determine a threshold where Reachy holds the object enough to manipulate it without forcing too much on the gripper motor.
goto() function #Presentation #This function generates a trajectory between the present position and the goal position. This trajectory is then interpolated at a predefined frequency (100Hz) to compute all intermediary target positions that should be followed before reaching the final goal position. Depending on the interpolation mode chosen, you can have a better control over speed and acceleration.
The two interpolation modes that we use consist in working either linearly or with the minjerk function.
Both trajectories start and finish at the same point but don\u0026rsquo;t follow the same intermediate positions. The minimum jerk will slowly accelerate at the begining and slowly decelerate at the end. This makes the movements more natural.
The goto() function takes as arguments:
goal_positions: dictionnary whose items are the joints you want to move with their goal positions, duration: duration in seconds of the trajectory, starting_positions (optional): dictionary whose items are the joints you want to move with their starting positions. By default it is a dictionary where the keys are the joints requested goal_positions with their present position, sampling_freq (optional): sampling frequency in hz for the trajectory interpolation, 100Hz by default, interpolation_mode: interpolation mode used to interpolate the trajectory, either InterpolationMode.LINEAR or InterpolationMode.MINIMUM_JERK. The function doc is also available here.
Example #Let\u0026rsquo;s see an example of how to use it.
You will use the goto() to place the right arm at a right-angled position. First, make sure that the Reachy\u0026rsquo;s right arm is placed on a cleared table and that there will not be obstacles during its movement.
The setup should look like this:
Import everything needed to execute the goto():
from reachy_sdk.trajectory import gotofrom reachy_sdk.trajectory.interpolation import InterpolationModeDefine the dictionary for the right-angled position for the right arm, this will be the goal_positions argument of the *goto():
right_angled_position = {reachy.r_arm.r_shoulder_pitch: 0,reachy.r_arm.r_shoulder_roll: 0,reachy.r_arm.r_arm_yaw: 0,reachy.r_arm.r_elbow_pitch: -90,reachy.r_arm.r_forearm_yaw: 0,reachy.r_arm.r_wrist_pitch: 0,reachy.r_arm.r_wrist_roll: 0,}For the goto() to work, the right arm\u0026rsquo;s joints need to be in stiff mode.
reachy.turn_on('r_arm')Then the goto(), here we use a duration of 1 second with the minimum jerk as interpolation mode but feel free to change it.
goto(goal_positions=right_angled_position,duration=1.0,interpolation_mode=InterpolationMode.MINIMUM_JERK)The result should look like this:
Your browser does not support the video element.
Don\u0026rsquo;t forget to put the right arm\u0026rsquo;s joints back to the compliant mode. Place your hand below the right arm\u0026rsquo;s gripper to prevent the arm from falling hard on the table.
reachy.turn_off('r_arm')`}),e.add({id:88,href:"/sdk/first-moves/",title:"First Moves",description:"Basic steps to get started with the SDK. Learn how to control each part of Reachy.",content:""}),e.add({id:89,href:"/sdk/application/idle/",title:"Idle App",description:"A simple application to make Reachy move autonomously.",content:`What is this application #The idle application defines an idle mode for Reachy which can run autonomously.
This project has been thought to:
be able to make Reachy move immediately after the robot setup, without having to do any code start to elaborate a way to define behaviors for human-robot interaction, making independant components that can be reused and integrated in more complex programs. The idea is to be able to integrate this idle mode in any project requiring such a state, without having to re-code this behavior again and again. The source can be found in the hello-world GitHub repository.
How to install and run the application #Install #Clone the repository and install with pip.
cd ~/devgit clone https://github.com/pollen-robotics/hello-world.gitcd hello-worldpip3 install -e .Run the application #You can run the application directly with Python.
cd ~/dev/hello-worldpython3 -m hello_world.helloOr call launch.bash
cd ~/dev/hello-worldbash launch.bashWhat this bash file does is just making sure that reachy_sdk_server.service (Reachy’s core code) is started and calling the application with the Python command given above.
Define service #You can also setup a service to start the application automatically at boot or to control the application directly with the dashboard.
To do that, just use the provided bash file.
cd ~/dev/hello-worldbash setup-service.bashHowever be careful if you start the application automatically at boot, you need to make sure that the robot is in place and that nothing could enter in collision with it while it is moving.
We recommend to play a few times with the application using the Python calling before using the service, to be familiar with the hello world.
Good practice #It is important to give Reachy enough space to move, for the robot and for the people around.
First, the robot needs to be able to have its arms straight along its body. This means for example that there cannot be a table in front of Reachy, or objects that you could block the trajectory of its movements. We recommend using the behavior player to play each behavior independently first, to get a sense of what each movement is doing. This will show you what space the robot needs to run the application safely. See the behaviors section to learn how to use the behavior player. Safety first #You need to understand that no intelligence has been put in the playing of the behaviors, meaning that the movements are hard-coded. So if during its movements, someone or something comes in the way of Reachy, the robot will not stop its movement. Make sure that no one will be in the movement area of Reachy when the application is running. Always have someone around the robot when the application is running, don’t let the robot alone. Behaviors #The application is a composition of implemented behaviors. Here we will present each behavior independently.
Existing behaviors #Currently nine behaviors are implemented:
asleep: Reachy moves just a bit its arm along its body as if it was breathing, with the head looking down. look_hand: Reachy moves its gripper and look at it. lonely: Reachy looks around and act sad at the end. scratch: Reachy scratches its forearm. tshirt: Reachy grabs its T-shirt, and put it back in place. sweat_head: Reachy touches wipe its head as if it was too hot. sneeze: Reachy sneezes with a head movement. whistle: Reachy whistles a tune cheerfully. hello: Reachy waves its hand to say hello. To play any of these behaviors without having to use the app, you can use the behavior_player script.
For example, to play sneeze:
cd ~/dev/hello-worldpython3 -m hello_world.behavior_player sneezeIdle #The idle behavior is the behavior played by the application in the hello script (you can consider hello to be the main file for the application). Idle is composed of sub-behaviors, each of them being the behaviors presented above.
Here is the implementation of Idle, taken from idle.py:
class Idle(Behavior):\u0026quot;\u0026quot;\u0026quot;Idle class.\u0026quot;\u0026quot;\u0026quot;def __init__(self, name: str, reachy, sub_behavior: bool = False) -\u0026gt; None:\u0026quot;\u0026quot;\u0026quot;Initialize the behavior.\u0026quot;\u0026quot;\u0026quot;super().__init__(name, reachy=reachy, sub_behavior=sub_behavior)logging.basicConfig(level=logging.INFO)self._logger = logging.getLogger()self.reachy = reachyself.asleep_behavior = Asleep(name='asleep', reachy=self.reachy, sub_behavior=True)self.behaviors = {'look_hand': LookHand(name='look_hand', reachy=self.reachy, sub_behavior=True),'lonely': Lonely(name='lonely', reachy=self.reachy, sub_behavior=True),'scratch': Scratch(name='scratch', reachy=self.reachy, sub_behavior=True),'tshirt': Tshirt(name='tshirt', reachy=self.reachy, sub_behavior=True),'sweat_head': SweatHead(name='sweat_head', reachy=self.reachy, sub_behavior=True),'sneeze': Sneeze(name='sneeze', reachy=self.reachy, sub_behavior=True),'whistle': Whistle(name='whistle', reachy=self.reachy, sub_behavior=True),'hello': Hello(name='hello', reachy=self.reachy, sub_behavior=True)}async def run(self):\u0026quot;\u0026quot;\u0026quot;Implement the behavior.\u0026quot;\u0026quot;\u0026quot;while True:asleep = await self.asleep_behavior.start()self._logger.info('Playing asleep behavior.')await asleepself.reachy.turn_on('reachy')random_sub_behavior = np.random.choice(list(self.behaviors.keys()))self._logger.info(f'Playing sub behavior {random_sub_behavior}')await self.behaviors[random_sub_behavior]._run()You can see in the init that the nine behaviors presented before are imported and defined as sub behaviors.
What the idle behavior is actually doing is defined in the run method: when doing idle, Reachy will alternate between the asleep behavior and one of the other eight behavior, picked randomly.
If you want to remove a behavior from idle, just comment it in the definition of self.behaviors.
Implement your own behavior #It is also possible for you to implement your own behavior and to add it to the idle behavior.
What you need to know is that your class defining your new behavior should inherit from the Behavior class, define an __init__, a run and a terdown method. More info on the README of the hello-world repository.
Each existing behavior have been implemented only using [Reachy’s Python SDK], whether it was by using goto or [look_at], or by [recording and replaying movements]. Take a look at how the behaviors have been implemented to get some inspiration.
Other #Run the application on any computer #Since all the application has been developed using [reachy-sdk], it is not mandatory to run the application directly on Reachy’s computer. As long as reachy-sdk is installed on your machine, you can run the application locally on your computer by changing Reachy_IP variable in the hello file.
Sound #As you will notice, when playing the behaviors, some of them also play sounds simultaneously! This is the case of asleep, sneeze and whistle. Feel free to add sounds to your behaviors or the existing ones using the playsound tool in the project.
`}),e.add({id:90,href:"/sdk/application/face-tracking/",title:"Face Tracking",description:"Autonomous application developped with the Python SDK where Reachy tracks faces.",content:`What is this application #The face tracking project is an autonomous application in which Reachy will detect faces in its field of view and track the detected face that is closet to it.
This can be used as is to make demo with the robot, show the capabilities of the Orbita actuator or serve as a brick to build more complex and interactive applications.
The source code can be found in the reachy-face-tracking GitHub repository.
How to install and run the application #Install #Clone the repository and install it on your Reachy with pip.
cd ~/devgit clone https://github.com/pollen-robotics/reachy-face-tracking.gitcd reachy-face-trackingpip3 install -e .Run the application #You can run the application directly with Python.
cd ~/dev/reachy-face-trackingpython3 -m reachy-face-tracking.face_tracking_launcherOr call launch.bash
cd ~/dev/reachy-face-trackingbash launch.bashWhat this bash file does is just making sure that reachy_sdk_server.service (Reachy’s core code) is started and calling the application with the Python command given above.
Define service #You can also setup a service to start the application automatically at boot or to control the application directly with the dashboard.
To do that, just use the provided bash file.
cd ~/dev/reachy-face-trackingbash setup-service.bashHowever be careful if you start the application automatically at boot, make sure that someone is still around in case the head makes an unexpected movements.
We recommend to play a few times with the application using the Python calling before using the service, to be familiar with the face tracking.
Good practice #Don\u0026rsquo;t let it run for hours. With time, the neck motors will heat. A break from time to time (at least 10 min each hour) to let the motors cool down a bit will help them. Use the face detection tester script to check if the system can correctly detect faces. How it is working #To explain briefly how the application is working.
The application is basically a loop composed of three steps:
We grab Reachy’s last frame available from the right camera For this frame, we use Reachy’s Edge TPU to infer if there are faces or not, using a face detection model provided by Google. If no faces are detected in the frame, then the head does nothing. If faces are actually detected, we check the size of the window for each face. If the size is less than the tracking_threshold, then we ignore the face. This prevent from tracking people too far. You can check how the tracking_threshold applies with the face detection tester script. For the remaining faces, we pick the one whose detection window is the biggest and we control Orbita (Reachy’s neck) so that the center of the face gets in the center of the image. `}),e.add({id:91,href:"/sdk/application/",title:"Application",description:"Check out the different autonomous applications you can run on your Reachy robot.",content:""}),e.add({id:92,href:"/sdk/appendix/support/",title:"Support",description:"Get support while using the Python SDK.",content:`FAQ #Check if your question is part of our [FAQ].
Forum #Join our Forum if you have any questions, maybe someone has already asked the same question or other people could benefit from the answer!
👉 Any questions relative to your development with Reachy?Go to Pollen Community Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:93,href:"/sdk/appendix/apis/",title:"APIs",description:"Reachy SDK APIs documentation.",content:`The full APIs generated by Sphinx is available at https://pollen-robotics.github.io/reachy-sdk/.
`}),e.add({id:94,href:"/sdk/appendix/",title:"Appendix",description:"Check Reachy SDK API and get support while using the Python SDK.",content:""}),e.add({id:95,href:"/dashboard/introduction/introduction/",title:"What is the dashboard?",description:"Introduction to Reachy's dashboard.",content:`We developed Reachy\u0026rsquo;s dashboard to give you an overview of the state of your Reachy (which motors are detected, what services are running, what are the motors temperatures\u0026hellip;) as well as giving you the possiblity to access quickly some features (changing a robot\u0026rsquo;s part compliance for example).
This tool has been thought to help you start easier with the robot and facilitate quick debugging.
What it provides?
Easy setup when you just received your Reachy Reachy will emit its own wifi network Reachy-AP to which you will be able to connect. From this you can easily connect Reachy to your wifi network and [get started with the robot]. No need to plug a computer screen, keyboard and mouse to the robot.
First debug step without having to open a terminal If you are not able to connect to Reachy using its Python SDK, it probably means that something went wrong when Reachy\u0026rsquo;s software started. Whether it is because one of Reachy\u0026rsquo;s cable is disconnected or because Reachy\u0026rsquo;s motors has not been turned on, the dashboard will try to tell you what is going on with Reachy without having to type any code. If the problem is not as simple, you also have access to Reachy\u0026rsquo;s services logs to get more information on the problem your robot is encountering.
Easy access to basic information from the robot Monitor motor positions and temperatures, change motors compliance or activate Reachy\u0026rsquo;s fans in one click.
Manage network connection Handle wifi network connection, manage Reachy\u0026rsquo;s hotspot to connect to the robot even when there is no Internet available.
And much more! Because the dashboard is open source like Reachy\u0026rsquo;s hardware and software, you can customize the dashboard and create your own features!
Access the dashboard #From the robot:
Access the dashboard at 127.0.0.1:3972 from any web browser.
From any other device (computer, phone, tablet, \u0026hellip;) on the same network as the robot:
Access the dashboard at \u0026lt;robot-ip\u0026gt;:3972 from any web browser.
Features Overview #The dashboard is composed of five pages:
[Debug]: indicates if a cable was disconnected or if Reachy\u0026rsquo;s motors were off when Reachy booted, [Dashboard]: displays the present position and temperature of each joint, allows you to control Reachy\u0026rsquo;s fans and the joints compliance, [Services]: lets you check which services are running in your robot. You can restart, stop each service and access their logs easily, [Wifi]: lets you manage Reachy\u0026rsquo;s wireless connection. You can connect your robot to a new wifi network or control its hotspot. [Applications]: lets you manage Reachy\u0026rsquo;s autonomous applications. Just with Reachy\u0026rsquo;s services, you start, stop and access the logs for each application that you installed. For now, only the Idle and Face tracking applications are available. On each page, the configuration of the robot will also be displayed (e.g. whether your robot is a full kit, starter kit, \u0026hellip;)
More information is available for each page in the [content section].
`}),e.add({id:96,href:"/dashboard/introduction/first-connection/",title:"First Connection",description:"First connection to Reachy through the dashboard.",content:`When you receive your Reachy, it can be quite confusing at first to get your hands on, that is where the dashboard comes handy.
The dashboard will allow you to setup your robot easily, without needing to plug a computer screen, mouse and keyboard.
Reachy\u0026rsquo;s hotspot #When Reachy does not know any wifi network at boot, its hotspot is activated by default, meaning Reachy emits its own wifi. By default, the name of Reachy\u0026rsquo;s hotspot is Reachy-AP. You can connect to the hotspot with your laptop or computer just like with any wireless network.
Default password to connect to Reachy-AP: Reachy-AP When using its hotspot, Reachy\u0026rsquo;s IP address is always the same, meaning that if you want to ssh to the robot or use the [teleoperation], you won\u0026rsquo;t have to search for Reachy\u0026rsquo;s IP address.
Default Reachy\u0026rsquo;s IP address when in hotspot mode: 10.42.0.1
Connect Reachy to your wifi network #Once connected to the hotspot, you can easily access Reachy\u0026rsquo;s dashboard and connect the robot to your wifi. To do that:
[Turn the robot on] With your phone or computer, connect to the wifi network Reachy-AP (password is Reachy-AP) With the device connected, goto the page http://10.42.0.1:3972/wifi The page should look like this:
Then
Select the wifi network you want Reachy to connect to. The wifi networks available should be in the dropdown under SSID. Enter your wifi password. If you need, you can use the reveal password option. If the password is correct, the hotspot will be turned off and Reachy will be connected to your network. If you entered an incorrect password, the hotspot will be turned on again, giving you the opportunity to try the connection again. Then to access the dashboard on the newly connected network, you will need Reachy\u0026rsquo;s new IP address. There are two ways to get that:
read the IP on the LCD screen placed in Reachy\u0026rsquo;s shirt, if it is installed. find Reachy\u0026rsquo;s IP using an other tool, as explained in [this page]. To access the dashboard from your network, go to: http://\u0026lt;your-reachy-ip\u0026gt;:3972
In the next sections, you will learn the content of each page composing the dashboard.
`}),e.add({id:97,href:"/dashboard/content/applications/",title:"Applications",description:"Dashboard page to control Reachy's applications.",content:`The page applications is dedicated to the autonomous applications installed for Reachy.
Having this page is useful to control start some autonomous application for Reachy easily.
Content #In this page, one card will be created per Reachy\u0026rsquo;s application. Typically the page will looks like the following:
For each application, it will be indicated whether the application is currently running or not and three buttons will be available:
Restart: restarts the application, Stop: stops the application, Show logs: displays the logs of the application. Having the logs is useful for debugging, you will be able to see the error messages on what is causing the problem as if you were launching Reachy\u0026rsquo;s code in a terminal. ⚠️ ⚠️ Be careful not to start multiple applications at the same time!
Currently, only two autonomous applications are available: Idle and Face tracking.
Notes #💡 If you want to developp your own Reachy\u0026rsquo;s application and be able to control it on this page, you will have to define a service starting your application. The service name shoud start with app_reachy_ \u0026ndash;user mode. Check the repository of the Hello world and Face tracking projects to learn how to build such applications.
`}),e.add({id:98,href:"/dashboard/content/dashboard/",title:"Dashboard",description:"Dashboard page displaying the present position and temperature of each joint and allowing to control Reachy's fans and joints compliance.",content:`The dashboard page is only accessible if the tools in the debug page found no missing motors or force sensors. It will allow you to get basic information from Reachy\u0026rsquo;s motors, change their compliance and control Reachy\u0026rsquo;s fans.
The page typically looks like the following:
It is composed of three parts:
Temperatures and positions displayer Compliance controller Fans controller Temperatures and positions displayer #The displayer is composed of one card per robot part (either Left Arm, Right Arm or Head).
For each card, the temperature (in Celsius) and position (in degrees) of each motor composing the part will be displayed in real time and refreshed every second.
It is useful in cases where for example you want to check if the arms\u0026rsquo; joints are installed correctly or you are using Reachy and want to monitor the motors\u0026rsquo; temperatures.
For each motor, if the temperature is above 46°C, the temperature color will turn to red, indicating you that the motor starts to heat.
Compliance controller #You can change the compliance of each robot\u0026rsquo;s part easily with the compliance controller. For each part available in the dropdown, three compliance options are available:
Turn on: put each motor composing the part in stiff mode, Turn off: put each motor composing the part in compliant mode, Turn off smoothly: first reduce the torque limit of each motor and then put each motor composing the part in compliant mode. This is the preferred method to put the the part in compliant, the risk of damaging a piece is greatly reduced. More information on the compliance of the robot is available [here].
Fans controller #You can also turn on/off Reachy\u0026rsquo;s fans. The fans are triggered automatically when a motor\u0026rsquo;s temperature reaches 55°C but when you know you will be using the robot for a bit of time, it might be useful to turn them on sooner.
`}),e.add({id:99,href:"/dashboard/content/debug/",title:"Debug",description:"Dashboard page indicating if a cable was disconnected or if Reachy's motors were off when Reachy booted.",content:`The debug page is the dashboard\u0026rsquo;s home page. It will indicate you if one of Reachy\u0026rsquo;s motor or force sensor is disconnected or if you forgot to turn on Reachy\u0026rsquo;s motors before booting its computer. Using this page is a good first step in debug if you are not able to connect to Reachy using the Python SDK or the VR for example.
Content #In this page, one card will be created per Reachy\u0026rsquo;s part. We consider that each Reachy\u0026rsquo;s arm represent a part and that the head is another part. So for example if you have a Full Kit Reachy, your robot will be composed of three parts: Left Arm, Right Arm and Head. If you are working with a Starter Kit Right Reachy, your robot will be composed of two parts: Right Arm and Head.
A debug page for a Full Kit Reachy will typically look like this:
The content of each card is what will change depending on what is going on with your robot.
Missing motors or force sensor #For each part, the system will check at boot or when reachy_sdk_server.service (Reachy\u0026rsquo;s main service) is started whether each motor or force sensor required by the part is detected. If a motor or a force sensor is not detected, it probably means that a cable is disconnected. The dashboard will tell you which motor or force sensor is faulty.
For example, we disconnected on the right arm the cable between the elbow pitch and the forearm yaw joints, here is what the dashboard is indicating:
As you can see, each motor after the elbow pitch joint is missing whereas only one cable was disconnected, this is because the motors are connected in serial in Reachy\u0026rsquo;s arms, so disconnecting one motor will unpower the next ones in the arm chain.
How to solve this #We made dedicated pages explaining how a motor cable or a foce sensor can be reconnected. The link to the page will appear on the page along with the name of the disconnected motor.
When multiple motors are indicated as missing, try to look first around the first one in the list to check if a cable is disconnected.
When each module is missing #The page might tell you that each motor and force sensor in Reachy is missing, like the following:
If this happens, it is probably because you forgot to turn Reachy\u0026rsquo;s motors on before booting its computer or because reachy_sdk_server.service is not started.
If it is because the motors were not turned on before Reachy\u0026rsquo;s computer, just use the switch in Reachy\u0026rsquo;s back to turn them on and then go to the service page to restart reachy_sdk_server.service.
If everything looks good #If no module is missing, then a button \u0026ldquo;Connect to Reachy\u0026rdquo; should be available as below.
Pressing this button will redirect you to the dashboard page where you will be able to monitor the motors temperatures and positions, control the fans or the joints compliance. More details on the [dashboard page].
If eveything looks good and you are still not able to connect to Reachy correctly, don\u0026rsquo;t hesitate to check the Help section of the documentation.
Notes #⚠️ The detection is only performed by the system when the motors are turned on using the switch in Reachy\u0026rsquo;s back. Thus if a cable is disconnected during manipulation, the dashboard will not be able to detect it. If you are not able to connect to Reachy and the debug page still tells you that each Reachy\u0026rsquo;s part looks good, turning off and on Reachy\u0026rsquo;s motors might be worth a shot.
⚠️ The detection of the missing motors and force sensors only works if Reachy\u0026rsquo;s code is launched using reachy_sdk_server.service in \u0026ndash;user mode (default behavior). For the ROS users, if you work directly with the launch file, the page will tell you that every motor and force sensor is missing.
`}),e.add({id:100,href:"/dashboard/content/services/",title:"Services",description:"Dashboard page to control Reachy's services.",content:`The page services is dedicated to the services setup for Reachy. Working with services has the advantage of having Reachy\u0026rsquo;s code running automatically at boot whithout needing to open a terminal and start it yourself. However using the services can make debugging the robot more difficult because the code running for Reachy is \u0026ldquo;hidden\u0026rdquo;, that is why we made this page.
Having this page is useful when something is going wrong with Reachy. For example, if you went on the debug page and you were told that a motor was disconnected, you can reconnect the motor indicated and restart Reachy\u0026rsquo;s code using the button restart of reachy_sdk_server.service. This way you won\u0026rsquo;t have to reboot Reachy\u0026rsquo;s computer just to restart its code. Or if you forgot to turn on Reachy\u0026rsquo;s motors before booting, you can just restart the service.
Content #In this page, one card will be created per Reachy\u0026rsquo;s service. Typically the page will looks like the following:
For each service, it will be indicated whether the service is currently running or not and three buttons will be available:
Restart: restarts the service, Stop: stops the service, Show logs: displays the logs of the service. Having the logs is useful for debugging, you will be able to see the error messages on what is causing the problem as if you were launching Reachy\u0026rsquo;s code in a terminal. Notes #💡 Only services whose names start with reachy_ and in \u0026ndash;user mode will be displayed on the page.
For more information on how to handle the Reachy\u0026rsquo;s services and what they are used for, check the [services page].
`}),e.add({id:101,href:"/dashboard/content/wifi/",title:"Wifi",description:"Dashboard page to manage Reachy's wireless connection.",content:`The wifi page of the dashboard lets you handle the network connection of the robot and typically looks like the following:
There are four main elements on this page:
Connection card: this card will display whether Reachy is connected to the Internet with an ethernet cable or a wifi network (in which case it will tell you which wifi network) or if it is using its hotspot,
Wifi adder card: this card will help you connect Reachy to a wifi network. The dropdown will list each wifi network detected and you will be able to connect to the one you want by entering your wifi password in the corresponding box,
Reachy\u0026rsquo;s IP address card: this card will display Reachy\u0026rsquo;s IP address. If Reachy\u0026rsquo;s hotspot is activated, its IP address is fixed and is 10.42.0.1,
Hotspot toggle: this will allow you to turn on/off Reachy\u0026rsquo;s hotspot.
Reachy\u0026rsquo;s Hotspot #Reachy is able to emit its own wifi when needed. By default the hotspot is turned on when the dashboard is started and no wifi networks are known. This is the case when you first receive your Reachy for example. Having a hotspot is useful because it gives you the possibility to connect remotely to Reachy even when no wifi network is available.
When the hotspot is on, Reachy will emit its wifi under the network name Reachy-AP. The password to connect to it is the same as the network name, Reachy-AP (mind the capital letter, the password is case sensitive).
When the hotspot is on, Reachy always has the same IP address on the network: 10.42.0.1.
Changing wifi network #You can connect Reachy to a wifi network using the Wifi adder card.
When you change the wifi network, the following message will appear:
If you try to change the wifi network and fail to enter the correct password, Reachy will switch to hotspot mode and you will have to try again to update the wifi network by connecting to Reachy-AP.
Notes #💡 If you installed the dashboard yourself, you will need to forget previsouly known wireless networks on Reachy and only use the dashboard when handling wireless networks.
`}),e.add({id:102,href:"/dashboard/introduction/",title:"Introduction",description:"Introduction to Reachy's dashboard.",content:""}),e.add({id:103,href:"/dashboard/installation/",title:"Installation",description:"How to install Reachy's dashboard.",content:""}),e.add({id:104,href:"/dashboard/content/",title:"Content",description:"What you can find in Reachy's dashboard.",content:""}),e.add({id:105,href:"/dashboard/",title:"Dashboard",description:"Use the dashboard to check Reachy's status, debug Reachy's issues and start applications.",content:""}),e.add({id:106,href:"/docs/update/",title:"Update Reachy",description:"Learn how to update Reachy's software.",content:""}),e.add({id:107,href:"/docs/update/update_packages/",title:"Update packages",description:"Update Reachy's software packages.",content:`Fetch repositories on Github Desktop #All the Github repositories of Reachy\u0026rsquo;s packages are cloned on Github Desktop. Simply find it on Reachy\u0026rsquo;s computer, select one by one the repositories and fetch to check if there are updates. Pull the changes in case updates are found.
The list of all Reachy\u0026rsquo;s packages which may require updates is available here:
👉 In case of major Reachy updates, it may happen some packages of the list are not cloned on your robot. Clone them from Github Desktop in the correct folder (reachy_ws/src or dev depending of the nature of the package). Rebuild ROS packages #To make sure the updates have been taken into account, build ROS packages after having pulled them.
cd ~/reachy_wscolcon build --symlink-installsource ~/.bashrc`}),e.add({id:108,href:"/docs/installation/",title:"What needs to be installed",description:"Software installation to control Reachy.",content:""}),e.add({id:109,href:"/docs/debug/",title:"I have a problem!",description:"Learn how to debug your problems with Reachy.",content:""}),e.add({id:110,href:"/docs/getting-started/",title:"Getting Started",description:"On first start.",content:""}),e.add({id:111,href:"/docs/debug/support/",title:"Support",description:"Get help and support for Reachy.",content:`Quick debug and FAQ #Forum #Join our Forum if you have any questions, maybe someone has already asked the same question or other people could benefit from the answer!
👉 Any questions relative to your development with Reachy?Go to Pollen Community Pollen Robotics support #For any specific questions concerning your robot or if you meet problems with the product, please contact us at support@pollen-robotics.com.
`}),e.add({id:112,href:"/sdk/",title:"Docs",description:"Discover the Python SDK for Reachy and its mobile base.",content:""}),e.add({id:113,href:"/docs/",title:"Docs",description:"Learn how to install and get started with Reachy.",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()